{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T17:45:29.372399Z",
     "start_time": "2020-02-25T17:45:29.369243Z"
    }
   },
   "source": [
    "<font size=4 color='blue'>\n",
    "\n",
    "# Clase 3, octubre 7 del 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='blue'>\n",
    "    \n",
    "## Generación de las muestras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font size=5 color='b'>\n",
    "\n",
    "1.  Se genera un conjunto de numeros aleatorios ($(x_1,y_1),(x_2,y_2),…,(x_n,y_n)$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:09.270565Z",
     "start_time": "2020-10-07T16:42:08.780217Z"
    }
   },
   "outputs": [],
   "source": [
    "#Se modelan un conjunto de datos (muestras)\n",
    "#En una versión futura del código, estos serán sustituidos por datos \n",
    "#medidos experimentalmente, y simplemente serán leidos.\n",
    "\n",
    "def generador_datos_simple(beta, m, desviacion):\n",
    "    \n",
    "    np.random.seed(3)                      # se fija para que los valores sean reproducibles\n",
    "    x = np.random.random(m) * 10           # x es arreglo con m numeros aleatorios entre 0 y 100\n",
    "    e = np.random.randn(m) * desviacion    # e es un error generado aleatoriamente\n",
    "    y = x * beta + e                       # se obtienen los valores de y \n",
    "                                           # x*beta genera una recta, sumando los errores, e, se alejan los puntos de la recta.     \n",
    "    return x.reshape((m,1)), y.reshape((m,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:09.477454Z",
     "start_time": "2020-10-07T16:42:09.271924Z"
    }
   },
   "outputs": [],
   "source": [
    "desviacion = 10\n",
    "beta = 4\n",
    "m = 5000   # numero de muestras\n",
    "\n",
    "x, y = generador_datos_simple(beta, m, desviacion)\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.scatter(x, y)\n",
    "plt.grid(True)\n",
    "plt.title('Distancia vs tiempo', size=24)\n",
    "plt.xlabel('Tiempo (s)', size=18)\n",
    "plt.ylabel('Distancia (cm)', size=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T17:53:57.795234Z",
     "start_time": "2020-02-25T17:53:57.789400Z"
    }
   },
   "source": [
    "<font size=4 color ='blue'>\n",
    "Se generan histogramas de los datos originales, tanto de (x) como de (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:09.806626Z",
     "start_time": "2020-10-07T16:42:09.479183Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(x, bins=30, edgecolor='black', alpha=0.5)\n",
    "plt.xlabel('tiempo(s)', fontsize=16)\n",
    "plt.ylabel('frecuencia', fontsize=16)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(y, bins=30, edgecolor='black', alpha=0.5)\n",
    "plt.xlabel('distancia(cm)', fontsize=16)\n",
    "plt.ylabel('frecuencia', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=2, color='blue'>\n",
    "    \n",
    "# Buscando la correlación entre las muestras:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Se tiene un conjunto de muestras (puntos) $(x_i, y_i)$, y se busca encontrar una función F que describa una posible correlación entre ellos. En una primera aproximación x (tiempo) es una variable independiente, mientras que y (distancia) depende de x.\n",
    "\n",
    "Para encontrar la correlación entre las muestras, proponemos un conjunto de funciones definidas mediante la siguiente relación lineal:\n",
    "\n",
    "$$ F(x, w, b) = b + w x $$\n",
    "  \n",
    "Vemos que esta relación funcional es derivable respecto a todas sus variables, $x, w, b$.\n",
    "\n",
    "\n",
    "La letra $w$ se emplea como abreviación de la palabra en inglés \"weight\", porque se relaciona con la importancia que tiene la variable $x$ en el valor de la función $F$. La letra $b$ es la abreviación de la palabra \"bias\" en inglés, y se refiere a la referencia respecto a cero de la función $F$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-05T18:20:56.725971Z",
     "start_time": "2020-02-05T18:20:56.721704Z"
    }
   },
   "source": [
    "<font size = 4>\n",
    "\n",
    "Para encontrar la función que describe la correlación entre los puntos, es necesario generar una métrica para describir qué tanto se acerca cada una de las funciones específicas (con valores definidos de $w$ y de $b$) a esta descripción.\n",
    "\n",
    "La métrica que se propone es la siguiente: $$ $$\n",
    "\n",
    "Para cada muestra $(x_i, y_i)$ se evalua $F(x_i,w,b)$ y se compara con el correspondiente valor $y_i$, la diferencia entre estos valores se eleva al cuadrado. $$ (y_i-F(x_i,w,b))^{2}$$\n",
    "\n",
    "\n",
    "Finalmente se calcula el promedio de este valor sobre todas las muestras, el cual definimos como error cuadrático medio (MSE, por sus siglas en inglés, mean squared error). \n",
    "Si $m$ es el número de muestras, el MSE queda como:\n",
    "\n",
    "$$MSE = \\dfrac{1}{m} ∑_{i=1}^{m}(y_i-F(x_i,w,b))^{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4, color='blue'>\n",
    "    \n",
    "En el siguiente código se implementa la generación del error cuadrático medio dada una función específica definida por los pesos iniciales $w = weight_0$, y $b = bias_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =4>\n",
    "    \n",
    "\n",
    "Los parámetros $w$ y $b$ se eligen al azar: \n",
    "\n",
    "``` python \n",
    "\n",
    "weight_0 = random.random()*10  \n",
    " \n",
    "bias_0 = random.random()*10   \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:09.812769Z",
     "start_time": "2020-10-07T16:42:09.808649Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)   # se usa la semilla para tener valores reproducibles\n",
    "\n",
    "#Initializing the variables of the function f\n",
    "\n",
    "weight_0 = np.random.random()*10\n",
    "bias_0 = np.random.random()*10\n",
    "\n",
    "print('w_0:', np.round(weight_0, 4), 'bias_0:', np.round(bias_0, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"blue\">\n",
    "\n",
    "Se grafica la correspondiente función $F(X,w,b)$, junto con los puntos que representan a las muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:10.015489Z",
     "start_time": "2020-10-07T16:42:09.814172Z"
    }
   },
   "outputs": [],
   "source": [
    "#1. The following arrays are generated for plotting the Function F(x, weight_0, bias_0)\n",
    "\n",
    "x_ = np.arange(0.0, 10.0, 0.1) #genera un cto de valores iniciando en 0.0, terminando en 10.0 y a pasos de 0.1\n",
    "y_ = weight_0*x_ + bias_0      # y es la función F(x_, w, b) generada con w_0 y b_0 \n",
    "\n",
    "#2. Using this function F, the residuos is calculated by comparin the calculated and measured values\n",
    "\n",
    "residuo = 0\n",
    "for i in range(len(x)):   # para cada muestra:\n",
    "    r = (y[i] - weight_0*x[i] - bias_0)**2\n",
    "    residuo += np.squeeze(r)\n",
    "residuo = residuo/len(x)\n",
    "\n",
    "print('residuo:', residuo)\n",
    "\n",
    "\n",
    "#3. Samples and function F are plotted\n",
    "\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.grid(True)\n",
    "    #Plotting function\n",
    "plt.plot(x_, y_, color='green', lw=4, label='F(x, w, b)') # x_, y_ son los valores que definen a F(X, w_0, b_0)\n",
    "plt.legend()\n",
    "    #Plotting samples\n",
    "plt.scatter(x, y);                                        # x, y son las muestras generadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T13:29:11.922916Z",
     "start_time": "2020-02-26T13:29:11.912479Z"
    }
   },
   "source": [
    "<font size=5, color='blue'>\n",
    "    \n",
    "> 1. Se varian los valores de los parámetros $w$ y $b$ buscando reducir el residuo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5, color='blue'>\n",
    "\n",
    "Se emplea el método de gradiente descendente para realizar esta variación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "    \n",
    "Los parámetros $w$ y $b$ se deben actualizar, de manera que el MSE disminuya. \n",
    "\n",
    "Los parámetros se actualizan usando la siguientes ecuaciones:\n",
    "\n",
    "$$ w := w - \\alpha \\dfrac{\\partial MSE(w, b)}{\\partial w}$$\n",
    "\n",
    "$$ b := b - \\alpha \\dfrac{\\partial MSE(w, b)}{\\partial b}$$\n",
    "\n",
    "$\\alpha$: tasa de aprendizaje, es un hiperparámetro del modelo, y controla la velocidad con que el modelo aprenderá a ajustar a los parametros $w$ y $b$.\n",
    "\n",
    "\n",
    "En este caso\n",
    "\n",
    "$$ MSE = \\dfrac{1}{m}∑_{i=1}^{m}(y_i-f(x_i))^{2} = \\dfrac{1}{m}∑_{i=1}^{m}(y_i - w x_i - b)^2 $$\n",
    "\n",
    "Entonces\n",
    "\n",
    "$$ \\dfrac{\\partial MSE(w, b)}{\\partial w} = \\dfrac{2}{m}∑_{i=1}^{m}[(w x_i + b -y_i)(x_i)]$$\n",
    "\n",
    "$$ \\dfrac{\\partial MSE(w, b)}{\\partial b} = \\dfrac{2}{m}∑_{i=1}^{m}[(w x_i + b -y_i)]$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:10.056829Z",
     "start_time": "2020-10-07T16:42:10.036187Z"
    }
   },
   "outputs": [],
   "source": [
    "#Function to update weight and bias\n",
    "\n",
    "def update_parameters(x, y, weight, bias, alfa, iteraciones):\n",
    "    \n",
    "    '''\n",
    "    Esta función actualiza los parámetros (w,b) usando gradient descent\n",
    "    \n",
    "    INPUT\n",
    "        x,y: muestras\n",
    "        weight: peso inicial\n",
    "        bias: bias inicial\n",
    "        alfa: learning rate\n",
    "        iteraciones: int que define el numero de veces a actualizar a los parámetros\n",
    "    OUTPUT\n",
    "        weights: lista con los pesos actualizados en cada iteración\n",
    "        biases: lista con los bias actualizados en cada iteración\n",
    "        residuos: lista con los residuos actualizados en cada iteración'''\n",
    "    \n",
    "    #1. inicializacion de parametros\n",
    "    \n",
    "    x = np.squeeze(x)\n",
    "    y = np.squeeze(y)\n",
    "    alfa = alfa\n",
    "    residuo = 0\n",
    "    d_w = 0.0\n",
    "    d_b = 0.0\n",
    "    m = len(x)  # especifica el número de muestras\n",
    "\n",
    "    #2. Especificaciones de las graficas\n",
    "    \n",
    "    plt.figure(figsize=(20,8))    \n",
    "\n",
    "    ax1 = plt.subplot(1,3,1)\n",
    "    ax2 = plt.subplot(1,3,2)\n",
    "    ax3 = plt.subplot(1,3,3)\n",
    "\n",
    "    ax1.grid(True)\n",
    "    ax2.grid(True)\n",
    "    ax3.grid(True)\n",
    "    \n",
    "    ax1.scatter(x, y) # grafica las muestras\n",
    "    ax1.set_title('Distancia vs tiempo', size=24)\n",
    "    ax1.set_xlabel('Tiempo', size=18)\n",
    "    ax1.set_ylabel('Distancia', size=18)\n",
    "\n",
    "        # Recta generada con los parametros iniciales\n",
    "\n",
    "    y_ = weight*x + bias     # es F(x, w, b)\n",
    "    \n",
    "    ax1.plot(x, y_, color='green', lw=4)\n",
    "    \n",
    "    #3. Se calcula el residuo\n",
    "    \n",
    "    weights = []      # se inicializan las listas weights, biases, residuos\n",
    "    biases = []\n",
    "    residuos = []\n",
    "    \n",
    "    for i in range(iteraciones):  \n",
    "\n",
    "        # calculo de derivadas y el residuo\n",
    "\n",
    "        for i in range(m):\n",
    "\n",
    "            d_w += 2*(weight*x[i]+bias- y[i])*x[i]      \n",
    "            d_b += 2*(weight*x[i]+bias-y[i])\n",
    "            residuo += (y[i]-weight*x[i]-bias)**2\n",
    "\n",
    "        residuo /= m\n",
    "        d_w /= m\n",
    "        d_b /= m\n",
    "        \n",
    "        weights.append(weight)      # se agregan los resultados calculados\n",
    "        biases.append(bias)\n",
    "        residuos.append(residuo)\n",
    "        \n",
    "        #4. Actualización de los parametros\n",
    "\n",
    "        weight = weight - alfa*d_w\n",
    "        bias = bias - alfa*d_b\n",
    "\n",
    "        # Recta generada con la actualizacion de los parametros\n",
    "        \n",
    "        y_ = weight*x + bias    # es F(x,w_actualizado, b_actualizado)\n",
    "        ax1.plot(x, y_, lw=4)\n",
    "\n",
    "        #5. Grafica de los residuos como función de uno de los parámetros (el peso)\n",
    "        \n",
    "        ax2.scatter(weight, residuo)\n",
    "        ax2.set_title('MSE vs weight', size=24)\n",
    "        ax2.set_xlabel('weight', size=18)\n",
    "        ax2.set_ylabel('MSE', size=18)\n",
    "\n",
    "        #6. Grafica de los residuos como función de uno de los parámetros (el bias)\n",
    "        \n",
    "        ax3.scatter(bias, residuo)\n",
    "        ax3.set_title('MSE vs bias', size=24)\n",
    "        ax3.set_xlabel('bias', size=18)\n",
    "        ax3.set_ylabel('MSE', size=18)\n",
    "\n",
    "    return weights, biases, residuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:12.807568Z",
     "start_time": "2020-10-07T16:42:10.074437Z"
    }
   },
   "outputs": [],
   "source": [
    "weight = weight_0 \n",
    "bias = bias_0 \n",
    "alfa = 0.001\n",
    "num_iter = 100\n",
    "\n",
    "weights_100, biases_100, residuos_100 = update_parameters(x, y, weight, bias, alfa, num_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T21:44:25.901099Z",
     "start_time": "2020-02-21T21:44:25.895259Z"
    }
   },
   "source": [
    "<font size=4, color='blue'>\n",
    "Se grafica el residuo como función de cada iteración en que se modificaron el bias y el peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:12.936440Z",
     "start_time": "2020-10-07T16:42:12.809025Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 8))\n",
    "plt.grid(True)\n",
    "plt.scatter(range(num_iter), residuos_100, color='blue')\n",
    "plt.title('MSE vs Iteración', size=20)\n",
    "plt.xlabel('Iteración', size=15)\n",
    "plt.ylabel('MSE', size=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T19:53:06.445592Z",
     "start_time": "2020-10-05T19:53:06.437464Z"
    }
   },
   "source": [
    "<font size=5, color='blue'>\n",
    "\n",
    "> 2. Evaluación del ajuste obtenido\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T21:45:26.197814Z",
     "start_time": "2020-02-21T21:45:26.192320Z"
    }
   },
   "source": [
    "<font size=4, color='blue'>\n",
    "El total de los datos son divididos en dos grupos: uno con el 90 % de los datos y el segundo con el restante 10 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "La funcion shuffle reordena de forma aleatoria la posición de un conjunto de datos en una lista.\n",
    "\n",
    "     x = [ 1, 5, 7, 3, 8]\n",
    "     shuffle(x) = [5, 8, 3, 1, 7]\n",
    "\n",
    " La funcion zip permite hacer conjuntos ordenados de datos combinando dos vectores de igual dimensión, por ejemplo\n",
    "\n",
    "     x = [1, 2, 3]\n",
    "     y = [5, 6, 7]\n",
    "    \n",
    "     zip(x, y) = ((1, 5), (2, 6), (3, 7))\n",
    "    \n",
    " De esta manera, junto con la funcion shuffle, se asegura que los datos correspondientes a $x$ y $y$ intercambian su posición de la misma manera.\n",
    " \n",
    " Por otra parte, la operación zip(*c)\n",
    " \n",
    "     (x, y) = zip(*c)\n",
    "     \n",
    "Separa a los datos $x$ e $y$ ya mezclados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:13.207289Z",
     "start_time": "2020-10-07T16:42:12.937893Z"
    }
   },
   "outputs": [],
   "source": [
    "#1. Los datos se cambian de posición aleatoriamente\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "c = list(zip(x, y))    # se juntan las muestras: x e y ---> (x,y)\n",
    "shuffle(c)             # se cambia el orden de las muestras (x,y)\n",
    "(x, y) = zip(*c)       # se separan las muestras: (x,y)---> x e y\n",
    "\n",
    "print('Se tienen', len(x), 'muestras en total')\n",
    "\n",
    "#2. Los datos se dividen\n",
    "\n",
    "samples_for_train = (x[0:int(0.90*len(x))], y[0:int(0.90*len(y))])\n",
    "print('Se van a usar', len(samples_for_train[0]), 'muestras para el ajuste')\n",
    "\n",
    "samples_for_test = (x[int(0.90*len(x)):], y[int(0.90*len(y)):])\n",
    "print('Se van a usar', len(samples_for_test[0]), 'muestras para probar')\n",
    "\n",
    "#3. Se grafican ambos conjuntos\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.grid(True)\n",
    "plt.scatter(samples_for_train[0], samples_for_train[1])\n",
    "plt.title('samples_for_train', size=20)\n",
    "plt.xlabel('Tiempo(s)', size =15)\n",
    "plt.ylabel('Distancia(cm)', size =15)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.grid(True)\n",
    "plt.scatter(samples_for_test[0], samples_for_test[1], color='red')\n",
    "plt.title('samples_for_test', size=20)\n",
    "plt.xlabel('Tiempo(s)', size =15)\n",
    "plt.ylabel('Distancia(cm)', size =15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =4, color = 'blue'>\n",
    "    \n",
    " ## Normalización de las muestras que se emplearan para el ajuste\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='b'>\n",
    "    \n",
    " Si se normalizan con 3 veces la desviacion estandar, el 99.7% de los datos tendrán valores entre -1 y 1. El rango con que se normaliza tambien se puede variar entre una desviación o dos desviaciones estandar. En el primer caso el 68 % de los datos tendrán valores entre -1 y 1, mientras que en el segundo caso este rango correspondera al 95 % de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T18:02:38.947376Z",
     "start_time": "2020-02-25T18:02:38.937805Z"
    }
   },
   "source": [
    "<font size=5, color='blue'>\n",
    "Normalizando con una desviación estandar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    " 1. Separación de muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:13.211390Z",
     "start_time": "2020-10-07T16:42:13.208760Z"
    }
   },
   "outputs": [],
   "source": [
    "x_ajustar = samples_for_train[0]     # samples_for_train es de la forma (x,y)\n",
    "y_ajustar = samples_for_train[1]     # aqui se separan: (x,y) ---> x e y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    " 2. Normalización de muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:13.228114Z",
     "start_time": "2020-10-07T16:42:13.213312Z"
    }
   },
   "outputs": [],
   "source": [
    "y_1 = (y_ajustar-np.mean(y_ajustar))/(1.0*np.std(y_ajustar))    \n",
    "x_1 = (x_ajustar-np.mean(x_ajustar))/(1.0*np.std(x_ajustar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    " 3. Histogramas de las muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:13.543720Z",
     "start_time": "2020-10-07T16:42:13.229891Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.grid(True)\n",
    "plt.hist(x_1, bins=30,color='red', edgecolor='b', alpha=0.5)\n",
    "plt.xlabel('tiempo (unidades relativas)', fontsize=14)\n",
    "plt.ylabel('frecuencia',fontsize=14)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.grid(True)\n",
    "plt.hist(y_1, bins=30,color='red', edgecolor='b', alpha=0.5)\n",
    "plt.xlabel('distancia (unidades relativas)',fontsize=14)\n",
    "plt.ylabel('frecuencia',fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T18:02:38.947376Z",
     "start_time": "2020-02-25T18:02:38.937805Z"
    }
   },
   "source": [
    "<font size=5, color='blue'>\n",
    "Normalizando con tres desviaciones estandar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    " 1. Normalización de muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:13.556016Z",
     "start_time": "2020-10-07T16:42:13.545162Z"
    }
   },
   "outputs": [],
   "source": [
    "y_3 = (y_ajustar-np.mean(y_ajustar))/(3.0*np.std(y_ajustar))\n",
    "x_3 = (x_ajustar-np.mean(x_ajustar))/(3.0*np.std(x_ajustar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    " 2. Histogramas de las muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:13.827762Z",
     "start_time": "2020-10-07T16:42:13.557092Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.grid(True)\n",
    "plt.hist(x_3, bins=30,color='red', edgecolor='b', alpha=0.5)\n",
    "plt.xlabel('tiempo(unidades relativas)',fontsize=14)\n",
    "plt.ylabel('frecuencia',fontsize=14)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.grid(True)\n",
    "plt.hist(y_3, bins=30,color='red', edgecolor='b', alpha=0.5)\n",
    "plt.xlabel('distancia(unidades relativas)',fontsize=14)\n",
    "plt.ylabel('frecuencia',fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T18:02:38.947376Z",
     "start_time": "2020-02-25T18:02:38.937805Z"
    }
   },
   "source": [
    "<font size=5, color='blue'>\n",
    "Normalizando con dos desviaciones estandar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    " 1. Normalización de muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:13.840781Z",
     "start_time": "2020-10-07T16:42:13.829346Z"
    }
   },
   "outputs": [],
   "source": [
    "y_2 = (y_ajustar-np.mean(y_ajustar))/(2.0*np.std(y_ajustar))\n",
    "x_2 = (x_ajustar-np.mean(x_ajustar))/(2.0*np.std(x_ajustar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    " 2. Histogramas de las muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:14.100192Z",
     "start_time": "2020-10-07T16:42:13.842074Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.grid(True)\n",
    "plt.hist(x_2,bins=30, color='red', edgecolor='b', alpha=0.5)\n",
    "plt.xlabel('tiempo(unidades relativas)', fontsize=14)\n",
    "plt.ylabel('frecuencia',fontsize=14)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.grid(True)\n",
    "plt.hist(y_2, bins=30,color='red', edgecolor='b', alpha=0.5)\n",
    "plt.xlabel('distancia(unidades relativas)',fontsize=14)\n",
    "plt.ylabel('frecuencia',fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T18:02:38.947376Z",
     "start_time": "2020-02-25T18:02:38.937805Z"
    }
   },
   "source": [
    "<font size=5, color='blue'>\n",
    "Trabajaremos entonces normalizando los datos con una desviación estandar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:13.211390Z",
     "start_time": "2020-10-07T16:42:13.208760Z"
    }
   },
   "outputs": [],
   "source": [
    "samples_train_x = samples_for_train[0]     # samples_for_train es de la forma (x,y)\n",
    "samples_train_y = samples_for_train[1]     # aqui se separan: (x,y) ---> x e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:14.111633Z",
     "start_time": "2020-10-07T16:42:14.101558Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_distance = np.mean(samples_train_y)\n",
    "std_distance = np.std(samples_train_y)\n",
    "\n",
    "samples_for_train_y = (samples_train_y-mean_distance)/std_distance\n",
    "\n",
    "mean_time = np.mean(samples_train_x)\n",
    "std_time = np.std(samples_train_x)\n",
    "\n",
    "samples_for_train_x = (samples_train_x-mean_time)/std_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:14.358683Z",
     "start_time": "2020-10-07T16:42:14.112816Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.grid(True)\n",
    "plt.hist(samples_for_train_x, bins=30,color='blue', edgecolor='b', alpha=0.5)\n",
    "plt.xlabel('Tiempo(unidades relativas)', fontsize=14)\n",
    "plt.ylabel('Frecuencia',fontsize=14)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.grid(True)\n",
    "plt.hist(samples_for_train_y, bins=30,color='blue', edgecolor='b', alpha=0.5)\n",
    "plt.xlabel('Distancia(unidades relativas)',fontsize=14)\n",
    "plt.ylabel('Frecuencia',fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4, color='blue'>\n",
    "Se vuelve a correr el ajuste de datos empleando el metodo de gradiente descendente, pero usando sólo el conjunto de datos correspondiente al 90 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:17.058485Z",
     "start_time": "2020-10-07T16:42:14.360442Z"
    }
   },
   "outputs": [],
   "source": [
    "#np.random.seed(3)\n",
    "weight_0 = np.random.random()\n",
    "bias_0 = np.random.random()\n",
    "alfa = 0.04\n",
    "num_iter = 100\n",
    "\n",
    "weights_train, biases_train, residuos_train = update_parameters(samples_for_train_x, \n",
    "                                                                samples_for_train_y, \n",
    "                                                                weight_0, bias_0, alfa, num_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T21:48:14.609543Z",
     "start_time": "2020-02-21T21:48:14.599770Z"
    }
   },
   "source": [
    "<font size=4, color='blue'>\n",
    "Graficar el error cuadrático medio obtenido como función de la iteración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:17.197759Z",
     "start_time": "2020-10-07T16:42:17.062123Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 8))\n",
    "plt.grid(True)\n",
    "plt.scatter(range(num_iter), residuos_train, color='blue')\n",
    "plt.title('MSE vs iteración', size=20)\n",
    "plt.xlabel('iteración', size=15)\n",
    "plt.ylabel('MSE', size=15)\n",
    "plt.legend(['MSE train'],loc=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:17.203685Z",
     "start_time": "2020-10-07T16:42:17.199975Z"
    }
   },
   "outputs": [],
   "source": [
    "def residuo(x, y, weight, bias):\n",
    "    r = 0                                # el residuo se inicializa en 0\n",
    "    m = len(x)                           # m indica el número de muestras\n",
    "    for i in range(m):\n",
    "        r = (y[i]-weight*x[i]-bias)**2\n",
    "        r += np.squeeze(r)\n",
    "    r /= m  \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:17.263474Z",
     "start_time": "2020-10-07T16:42:17.205297Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Residuo mas pequeño que se obtuvo durante el ajuste =  %.5f\" \\\n",
    "      %np.squeeze(residuo(samples_for_train_x, samples_for_train_y, weights_train[-1], biases_train[-1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T21:50:17.258618Z",
     "start_time": "2020-02-21T21:50:17.253823Z"
    }
   },
   "source": [
    "<font size=4, color='blue'>\n",
    "Con los valores óptimos del bias y el peso se calcula el error cuadrático medio que se obtiene con el 10 % de los datos restantes (conjunto test)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T23:46:16.978156Z",
     "start_time": "2020-10-05T23:46:16.973573Z"
    }
   },
   "source": [
    "<font size=4, color='black'>\n",
    "\n",
    "Para calcular el residuo asociado a las samples_for_test, estas se normalizan con los parámetros (valore medio y desviación estandar) utilizados para normalizar los datos de las samples_for_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:17.276180Z",
     "start_time": "2020-10-07T16:42:17.265788Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test = (samples_for_test[1]-mean_distance)/std_distance\n",
    "x_test = (samples_for_test[0]-mean_time)/std_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4, color='blue'>\n",
    "\n",
    "Con los valores óptimos obtenidos para el peso y el bias, evaluamos ahora el residuo que se obtiene las muestras_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:17.292225Z",
     "start_time": "2020-10-07T16:42:17.278175Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Residuo =  %.5f\" %np.squeeze(residuo(x_test, y_test, weights_train[-1], biases_train[-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T19:53:06.445592Z",
     "start_time": "2020-10-05T19:53:06.437464Z"
    }
   },
   "source": [
    "<font size=5, color='blue'>\n",
    "\n",
    "> 3. Otra forma de evaluar el ajuste obtenido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4, color='blue'>\n",
    "   \n",
    "En este caso, las muestras seleccionadas para hacer el ajuste se dividen en dos grupos:\n",
    "\n",
    "El 90 % (este valor es solo un ejemplo) de ellos se emplea para hacer el ajuste (train set),\n",
    "    \n",
    "el 10 % restantes se emplean para evaluar el residuo que se obtiene en cada iteración del ajuste (validation set).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T14:51:27.055986Z",
     "start_time": "2020-10-06T14:51:27.050069Z"
    }
   },
   "source": [
    "<font size=4, color='black'>\n",
    "\n",
    "Modificamos la función que se tiene para actualizar el peso y se bias en cada ciclo.\n",
    "\n",
    "A esta nueva función se le proporciona la proporción de los datos que se van a emplear para validar el ajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:17.306912Z",
     "start_time": "2020-10-07T16:42:17.293773Z"
    }
   },
   "outputs": [],
   "source": [
    "#Function to update weight and bias\n",
    "\n",
    "def update_parameters_1(x, y, weight, bias, alfa, iteraciones, val_ratio=0.1):\n",
    "    \n",
    "    '''\n",
    "    Esta función actualiza los parámetros (w,b) usando gradient descent\n",
    "    Además separa a x e y en dos conjuntos: train y validation usando el val_ratio\n",
    "    \n",
    "    INPUT\n",
    "        x,y: muestras\n",
    "        weight: peso inicial\n",
    "        bias: bias inicial\n",
    "        alfa: learning rate\n",
    "        iteraciones: int que define el numero de veces a actualizar a los parámetros\n",
    "        val_ratio: porcentaje de los datos (x,y) a usar como conjunto de validación\n",
    "    OUTPUT\n",
    "        weights: lista con los pesos actualizados en cada iteración\n",
    "        biases: lista con los bias actualizados en cada iteración\n",
    "        residuos: lista con los residuos actualizados en cada iteración para el conjunto de entrenamiento\n",
    "        residuos_val: lista con los residuos actualizados en cada iteración para el conjunto de validación'''\n",
    "    \n",
    "    #1.  inicializacion de parametros\n",
    "    \n",
    "    x = np.squeeze(x)\n",
    "    y = np.squeeze(y)\n",
    "    alfa = alfa\n",
    "    residuo = 0\n",
    "    d_w = 0.0\n",
    "    d_b = 0.0\n",
    "    m = len(x)\n",
    "\n",
    "    #2.  Especificaciones de las graficas\n",
    "    \n",
    "    plt.figure(figsize=(13,8)) \n",
    "    plt.title('MSE vs iteracion', size=24)\n",
    "    plt.xlabel('iteracion', size=18)\n",
    "    plt.ylabel('MSE', size=18)\n",
    "    \n",
    "    #3. se dividen las muestras en los conjuntos train y validation\n",
    "    \n",
    "    ajustar_ratio = int((1.0-val_ratio)*len(x))  \n",
    "   \n",
    "    samples_train = (x[0:ajustar_ratio], y[0:ajustar_ratio])\n",
    "    samples_val = (x[ajustar_ratio:], y[ajustar_ratio:])\n",
    "    x = samples_train[0]\n",
    "    y = samples_train[1]\n",
    "    x_val = samples_val[0]\n",
    "    y_val = samples_val[1]\n",
    "    \n",
    "    #3.1 Normalización\n",
    "    \n",
    "    mean_x = np.mean(x)\n",
    "    std_x = np.std(x)\n",
    "    \n",
    "    mean_y = np.mean(y)\n",
    "    std_y = np.std(y)\n",
    "    \n",
    "    x = (x-mean_x)/std_x\n",
    "    y = (y-mean_y)/std_y\n",
    "    x_val = (x_val-mean_x)/std_x\n",
    "    y_val = (y_val-mean_y)/std_y\n",
    "\n",
    "    #4. se calcula el residuo\n",
    "       \n",
    "    weights = []\n",
    "    biases = []\n",
    "    residuos = []\n",
    "    residuos_val = []\n",
    "    \n",
    "    m_ajustar = len(x)    # numero de muestras para el ajuste\n",
    "    m_val = len(x_val)    # numero de muestras para validar\n",
    "    \n",
    "    for i in range(iteraciones):\n",
    "\n",
    "        # calculo de derivadas y el residuo\n",
    "        residuo = 0.0\n",
    "        residuo_val = 0.0\n",
    "        \n",
    "        for j in range(m_ajustar):\n",
    "\n",
    "            d_w += 2*(weight*x[j] + bias- y[j])*x[j]\n",
    "            d_b += 2*(weight*x[j]+bias-y[j])\n",
    "            residuo += (y[j]-weight*x[j] - bias)**2\n",
    "\n",
    "        residuo /= m_ajustar\n",
    "        d_w /= m_ajustar\n",
    "        d_b /= m_ajustar\n",
    "        \n",
    "        #calculo del residuo de las muestras de validación\n",
    "        \n",
    "        for j in range(m_val):\n",
    "            residuo_val += (y_val[j]-weight*x_val[j] - bias)**2\n",
    "        residuo_val /= m_val\n",
    "                      \n",
    "        weights.append(weight)             # se agregan los valores calculados a las listas\n",
    "        biases.append(bias)\n",
    "        residuos.append(residuo)\n",
    "        residuos_val.append(residuo_val)\n",
    "        \n",
    "        #5. Actualizacion de los parametros\n",
    "\n",
    "        weight = weight - alfa*d_w\n",
    "        bias = bias - alfa*d_b\n",
    "        \n",
    "        #6. Graficas del residuo en función de la iteración\n",
    "        \n",
    "        plt.grid(True)\n",
    "        plt.scatter(i, residuo, color='blue')\n",
    "        plt.scatter(i, residuo_val, color='orange')\n",
    "    plt.legend(['residuo', 'residuo_val'],loc=0);\n",
    "\n",
    "\n",
    "    return weights, biases, residuos, residuos_val, mean_x, std_x, mean_y, std_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:19.587148Z",
     "start_time": "2020-10-07T16:42:17.308020Z"
    }
   },
   "outputs": [],
   "source": [
    "#np.random.seed(2)\n",
    "weight_0 = np.random.random()\n",
    "bias_0 = np.random.random()\n",
    "alfa = 0.04\n",
    "num_iter = 100\n",
    "validacion_ratio = 0.5\n",
    "\n",
    "weights, biases, residuos, residuos_val, mean_x, std_x, mean_y, std_y = update_parameters_1 \\\n",
    "        (samples_for_train[0], samples_for_train[1], weight_0, bias_0, alfa, num_iter, validacion_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4, color='blue'>\n",
    "\n",
    "Con los valores óptimos obtenidos para el peso y el bias, evaluamos ahora el residuo que se obtiene las muestras_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:19.603294Z",
     "start_time": "2020-10-07T16:42:19.589275Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Residuo =  %.5f\" %np.squeeze(residuo(x_test, y_test, weights[-1], biases[-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T19:53:06.445592Z",
     "start_time": "2020-10-05T19:53:06.437464Z"
    }
   },
   "source": [
    "<font size=5, color='blue'>\n",
    "\n",
    "Inferencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4, color='black'>\n",
    "\n",
    "Dado el tiempo t podemos obtener una predicción (inferencia) del valor de la distancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:19.614801Z",
     "start_time": "2020-10-07T16:42:19.604835Z"
    }
   },
   "outputs": [],
   "source": [
    "def inference(t, w, b, mean_t, std_t, mean_y, std_y) :\n",
    "    t = (t-mean_t) / std_t \n",
    "    d = w * t + b\n",
    "    d = d * std_y + mean_y\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:19.628514Z",
     "start_time": "2020-10-07T16:42:19.616460Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tiempos = [1.65, 2.20, 4.5, 8.7]\n",
    "\n",
    "for t in tiempos :\n",
    "    distance = inference(t,weights[-1], biases[-1], mean_x, std_x, mean_y, std_y)\n",
    "\n",
    "    print (\"Para el tiempo de {0:5.3f} s la distancia inferida es {1:6.3f} cm \".format(t,distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "\n",
    "Vemos entonces que con el ajuste de una función al conjunto de puntos $(x_i, y_i)$ podemos hacer predicciones de valores y dado el valor de $x_i$. \n",
    "    \n",
    "Es decir, el sistema desarrollado \"aprendió\" la correlación que hay entre las $x_i$ y la $y_i$, y por ello puede hacer inferencias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T19:20:20.673227Z",
     "start_time": "2020-10-06T19:20:20.664698Z"
    }
   },
   "source": [
    "<font size=6 color='blue'>\n",
    "\n",
    "Inteligencia Artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T15:47:59.726986Z",
     "start_time": "2020-10-06T15:47:59.717971Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "Pasaremos conceptualmente del ajuste de datos a la Inteligencia Artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T15:49:32.315061Z",
     "start_time": "2020-10-06T15:49:32.306342Z"
    }
   },
   "source": [
    "<font size=4 color='black'>\n",
    "\n",
    "Esta transición la haremos empleando toda la matemática desarrollada en las celdas anteriores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "    \n",
    "En inteligencia artificial, un sistema es inteligente cuando después de ser entrenado con información que le es suministrada, es capaz de hacer inferencias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T15:43:45.263065Z",
     "start_time": "2020-10-06T15:43:45.257420Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    " \n",
    "Dada la dinámica en inteligencia artificial a nivel mundial, en el presente curso,\n",
    "    \n",
    "emplearemos la nomenclatura estandar que se emplea en el idioma Inglés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "\n",
    "Al analizar una area de estudio, se deben encontrar las conceptos que la identifican.\n",
    "    \n",
    "Se hace una cuantificación de estos conceptos definiendo variables que identifican a cada uno de ellos.\n",
    "    \n",
    "Existe un conjunto que estas variables $\\textbf{X}$ que son idependientes y que determinan al resto, a las cuales denominaremos como $\\textbf {Y}$.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "\n",
    "Se obtiene un cojunto $m$ de muestras de estas variables.\n",
    "\n",
    "Se genera un sistema de aprendizaje, al cual se le suministran estas muestras.\n",
    "\n",
    "Con esta información el sistema aprende y puede hacer inferencias.\n",
    "\n",
    "Por ejemplo, si se le presenta un nuevo dato X del área de estudio, el sistema puede predecir (inferir) los correspondientes valores de las variable Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "    \n",
    "El ejemplo que vimos de ajuste de una función a un conjunto de puntos $(x_i, y_i)$ lo traduciremos a un sistema de aprendizaje artificial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "    \n",
    "El área que analizamos corresponde al movimiento de un cuerpo. \n",
    "    \n",
    "Esta área la caracterizamos por los conceptos tiempo y distancia. \n",
    "    \n",
    "Definimos la viable $x$ para identificar al tiempo y la variable $y$ para idenficar la distancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T19:17:24.539641Z",
     "start_time": "2020-10-06T19:17:24.534327Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "Analizaremos un ejemplo de esta área."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "\n",
    "Tenemos un cuerpo, del cual se han obtenido $m$ muestras de estas variables. Cada muestra de este cuerpo la identificamos por la dupla $(x_i, y_i)$.\n",
    "    \n",
    "Generaremos un sistema de aprendizaje, en donde proponemos que la función $F(x)$ describe la relación entre estas variables. \n",
    "    \n",
    "Esta función puede tener diferentes formas. Por ejemplo:\n",
    "    \n",
    "$$F(x, w, b) = b + w x$$\n",
    "    \n",
    "o bien:\n",
    "    \n",
    "$$ F(x,w,b) = 1.7159*tanh(w*x+b) $$\n",
    "    \n",
    "o bien:\n",
    "    \n",
    "$$ F(x,weights, biases) = Artificial-Neural-Network (ANN)$$\n",
    "    \n",
    "o bien:\n",
    "    \n",
    "$$ F(x,weights, biases) = Supported-Vector-Machine(SVM)$$\n",
    "    \n",
    "o bien: \n",
    "    \n",
    "$$ F(x,weight, biases) = Decision-Tree $$\n",
    "    \n",
    "o bien:\n",
    "    \n",
    "$$ F(x,weight, biases) = Decision-Forest $$\n",
    "    \n",
    "entre otros.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "\n",
    "Dada la simplicidad de nuestros datos, para nuestro sistema de aprendizaje proponemos que la relación entre las vairables que describen nuestro sistema es una relación lineal, descrita por la función:\n",
    "    \n",
    " $$F(x, w, b) = b + w x$$\n",
    "    \n",
    "En la nomenclatura de inteligencia artificial, esto significa que nuestro problema se resuelve con una \"regresión lineal\" (Linear regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T19:24:11.171857Z",
     "start_time": "2020-10-06T19:24:11.167254Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "Estos son los datos que describen el movimiento de nuestro cuerpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:19.803177Z",
     "start_time": "2020-10-07T16:42:19.629895Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "desviacion = 10\n",
    "beta = 4\n",
    "m = 5000\n",
    "\n",
    "x, y = generador_datos_simple(beta, m, desviacion)\n",
    "plt.figure(figsize=(13,8))\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.grid(True)\n",
    "plt.title('Movimiento del cuerpo', size=24)\n",
    "plt.xlabel('X', size=18)\n",
    "plt.ylabel('Y', size=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T17:53:57.795234Z",
     "start_time": "2020-02-25T17:53:57.789400Z"
    }
   },
   "source": [
    "<font size=4 color ='blue'>\n",
    "Se generan histogramas de los las variables $x$ y $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:20.087349Z",
     "start_time": "2020-10-07T16:42:19.804968Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.grid(True)\n",
    "plt.hist(x, bins=30, edgecolor='black', alpha=0.5)\n",
    "plt.xlabel('X(s)', fontsize=16)\n",
    "plt.ylabel('frecuencia', fontsize=16)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.grid(True)\n",
    "plt.hist(y, bins=30, edgecolor='black', alpha=0.5)\n",
    "plt.xlabel('Y(cm)', fontsize=16)\n",
    "plt.ylabel('frecuencia', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T21:45:26.197814Z",
     "start_time": "2020-02-21T21:45:26.192320Z"
    }
   },
   "source": [
    "<font size=4, color='blue'>\n",
    "El total de los datos son divididos en dos grupos: uno con el 90 % de los datos y el segundo con el restante 10 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:20.338411Z",
     "start_time": "2020-10-07T16:42:20.089284Z"
    }
   },
   "outputs": [],
   "source": [
    "#1. Los datos se cambian de posición aleatoriamente\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "c = list(zip(x, y))    # se juntan las muestras: x e y ---> (x,y)\n",
    "shuffle(c)             # se cambia el orden de las muestras (x,y)\n",
    "(x, y) = zip(*c)       # se separan las muestras: (x,y)---> x e y\n",
    "\n",
    "print('Se tienen', len(x), 'muestras en total')\n",
    "\n",
    "#2. Los datos se dividen\n",
    "\n",
    "muestras_train = (x[0:int(0.90*len(x))], y[0:int(0.90*len(y))])\n",
    "print('Se van a usar', len(muestras_train[0]), 'muestras para el ajuste')\n",
    "\n",
    "muestras_test = (x[int(0.90*len(x)):], y[int(0.90*len(y)):])\n",
    "print('Se van a usar', len(muestras_test[0]), 'muestras para probar')\n",
    "\n",
    "#3. Se grafican ambos conjuntos\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.grid(True)\n",
    "plt.scatter(muestras_train[0], muestras_train[1])\n",
    "plt.title('Muestras_train', size=20)\n",
    "plt.xlabel('X(s)', size =15)\n",
    "plt.ylabel('Y(cm)', size =15)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.grid(True)\n",
    "plt.scatter(muestras_test[0], muestras_test[1], color='red')\n",
    "plt.title('Muestras_test', size=20)\n",
    "plt.xlabel('X(s)', size =15)\n",
    "plt.ylabel('Y(cm)', size =15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4, color='blue'>\n",
    "   \n",
    "Las muestras seleccionadas para hacer el entrenamiento se dividen en dos grupos:\n",
    "\n",
    "El 90 % (este valor es solo un ejemplo) de ellos se emplea para hacer el entrenamiento (training set),\n",
    "    \n",
    "el 10 % restantes se emplean para evaluar el $\\textbf {costo}$ que se obtiene en cada $\\textbf {época}$ del ajuste (validation set).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T14:51:27.055986Z",
     "start_time": "2020-10-06T14:51:27.050069Z"
    }
   },
   "source": [
    "<font size=4, color='black'>\n",
    "\n",
    "Generamos la función \"training\" que contiene la arquitectura que emplearemos para entrenar el sistema aprendizaje. \n",
    "    \n",
    "De momento, en esta función incluiremos también la métrica que emplearemos para obtener el entrenamiento, ejecutaremos el entrenamiento y generaremos las graficas del costo como función de la época. \n",
    "    \n",
    "Estas tres últimas acciones normalmente se definen por separado.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:55:39.474911Z",
     "start_time": "2020-10-07T16:55:39.459371Z"
    }
   },
   "outputs": [],
   "source": [
    "#Function to update weight and bias\n",
    "\n",
    "def training(x_train, y_train, weight, bias, alpha, epochs, val_ratio=0.1):\n",
    "    \n",
    "    '''\n",
    "    Esta función actualiza los parámetros (w,b) usando gradient descent\n",
    "    Además separa a x e y en dos conjuntos: train y validation usando el val_ratio\n",
    "    \n",
    "    INPUT\n",
    "        x,y: muestras\n",
    "        weight: peso inicial\n",
    "        bias: bias inicial\n",
    "        alfa: learning rate\n",
    "        epochs: int que define el numero de veces a actualizar a los parámetros\n",
    "        val_ratio: porcentaje de los datos (x,y) a usar como conjunto de validación\n",
    "    OUTPUT\n",
    "        weights: lista con los pesos actualizados en cada iteración\n",
    "        biases: lista con los bias actualizados en cada iteración\n",
    "        costs: lista con los residuos actualizados en cada iteración para el conjunto de entrenamiento\n",
    "        costs_val: lista con los residuos actualizados en cada iteración para el conjunto de validación'''\n",
    "    \n",
    "    #1. inicializacion de parametros\n",
    "    \n",
    "    x = np.squeeze(x_train)\n",
    "    y = np.squeeze(y_train)\n",
    "    alpha = alfa\n",
    "    costs = 0\n",
    "    d_w = 0.0\n",
    "    d_b = 0.0\n",
    "    m = len(x)\n",
    "\n",
    "    #2.  Especificaciones de las graficas\n",
    "    \n",
    "    plt.figure(figsize=(13,8)) \n",
    "    plt.title('Cost vs epoch', size=24)\n",
    "    plt.xlabel('epoch', size=18)\n",
    "    plt.ylabel('Cost', size=18)\n",
    "    \n",
    "    #3. Separación de muestras en los conjuntos train y validation\n",
    "    \n",
    "    train_ratio = int((1.0-val_ratio)*len(x))  \n",
    "   \n",
    "    samples_train = (x[0:train_ratio], y[0:train_ratio])\n",
    "    samples_val = (x[train_ratio:], y[train_ratio:])\n",
    "    x = samples_train[0]\n",
    "    y = samples_train[1]\n",
    "    x_val = samples_val[0]\n",
    "    y_val = samples_val[1]\n",
    "    \n",
    "    #3.1 Normalización\n",
    "    \n",
    "    mean_x = np.mean(x)\n",
    "    std_x = np.std(x)\n",
    "    \n",
    "    mean_y = np.mean(y)\n",
    "    std_y = np.std(y)\n",
    "    \n",
    "    x = (x-mean_x)/std_x\n",
    "    y = (y-mean_y)/std_y\n",
    "    x_val = (x_val-mean_x)/std_x\n",
    "    y_val = (y_val-mean_y)/std_y\n",
    "    \n",
    "    #4. Calculo del costo por epoca para ambos conjuntos\n",
    "       \n",
    "    weights = []\n",
    "    biases = []\n",
    "    costs = []\n",
    "    costs_val = []\n",
    "    \n",
    "    m_train = len(x)\n",
    "    m_val = len(x_val)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "\n",
    "        # calculo de derivadas y el residuo\n",
    "        cost = 0.0\n",
    "        cost_val = 0.0\n",
    "        \n",
    "        for j in range(m_train):\n",
    "\n",
    "            d_w += 2*(weight*x[j] + bias- y[j])*x[j]\n",
    "            d_b += 2*(weight*x[j]+bias-y[j])\n",
    "            cost += (y[j]-weight*x[j]-bias)**2\n",
    "\n",
    "        cost /= m_train\n",
    "        d_w /= m_train\n",
    "        d_b /= m_train\n",
    "        \n",
    "        #calculo del costo de las muestras de validación\n",
    "        \n",
    "        for j in range(m_val):\n",
    "            cost_val += (y_val[j]-weight*x_val[j]-bias)**2\n",
    "        cost_val /= m_val\n",
    "               \n",
    "       \n",
    "        weights.append(weight)      # se agregan los valores calculados a las listas\n",
    "        biases.append(bias)\n",
    "        costs.append(cost)\n",
    "        costs_val.append(cost_val)\n",
    "        \n",
    "        #5. Actualizacion de los parametros\n",
    "\n",
    "        weight = weight - alpha*d_w\n",
    "        bias = bias - alpha*d_b\n",
    "        \n",
    "        plt.grid(True)\n",
    "        plt.scatter(i, cost, color='blue')\n",
    "        plt.scatter(i, cost_val, color='orange')\n",
    "    plt.legend(['train', 'validation'],loc=0);\n",
    "\n",
    "    return weights, biases, costs, costs_val, mean_x, std_x, mean_y, std_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = muestras_train[0]\n",
    "y_train = muestras_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:55:42.445950Z",
     "start_time": "2020-10-07T16:55:40.103050Z"
    }
   },
   "outputs": [],
   "source": [
    "weight_0 = np.random.random()\n",
    "bias_0 = np.random.random()\n",
    "alpha = 0.04\n",
    "num_epochs = 100\n",
    "validation_ratio = 0.1\n",
    "\n",
    "weights, biases, cost, cost_val, mean_x, std_x, mean_y, std_y = training \\\n",
    "        (x_train, y_train, weight_0, bias_0, alpha, num_epochs, validation_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T19:53:06.445592Z",
     "start_time": "2020-10-05T19:53:06.437464Z"
    }
   },
   "source": [
    "<font size=5, color='blue'>\n",
    "\n",
    "Inferencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4, color='black'>\n",
    "\n",
    "Dado el tiempo t el sistema de aprendizaje puede predecir (inferir) del valor de la distancia para ese tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:23.089084Z",
     "start_time": "2020-10-07T16:42:23.085793Z"
    }
   },
   "outputs": [],
   "source": [
    "def inference(x, w, b, x_mean, x_std, y_mean, y_std) :\n",
    "    \n",
    "    x = (x-x_mean) / x_std \n",
    "    y = w * x + b\n",
    "    y = y * y_std + y_mean\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:23.101550Z",
     "start_time": "2020-10-07T16:42:23.090906Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tiempos = [1.65, 2.20, 4.5, 8.7]\n",
    "\n",
    "for t in tiempos :\n",
    "    distancia = inference(t,weights[-1], biases[-1], mean_x, std_x, mean_y, std_y)\n",
    "\n",
    "    print (\"Para el tiempo de {0:5.3f} s la distancia inferida es {1:6.3f} cm \".format(t,distancia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = muestras_test[0]\n",
    "y_test = muestras_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.squeeze(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:42:23.101550Z",
     "start_time": "2020-10-07T16:42:23.090906Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tiempos = x_test[:3]\n",
    "\n",
    "for t in tiempos :\n",
    "    distancia = inference(t,weights[-1], biases[-1], mean_x, std_x, mean_y, std_y)\n",
    "\n",
    "    print (\"Para el tiempo de {0:5.3f} s la distancia inferida es {1:6.3f} cm \".format(t,distancia))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

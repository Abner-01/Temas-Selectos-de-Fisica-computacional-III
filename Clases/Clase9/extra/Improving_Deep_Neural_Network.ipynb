{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='cornflowerblue'>\n",
    "    \n",
    " # Improving Deep Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    "> ## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "Para escoger a los hiperparametros en un modelo, como son\n",
    "\n",
    "    el numero de capas ocultas (intermedias), \n",
    "\n",
    "    el numero de nodos en cada capa oculta, \n",
    "\n",
    "    la tasa de aprendizaje, \n",
    "\n",
    "    las funciones de activacion para cada capa oculta, \n",
    "\n",
    "etcetera, se debe seguir un proceso iterativo para elegirlos 'correctamente'. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    ">> ### Train, development and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "  <img src=\"iter.png\" width=600 height=600 align = \"midle\" >     \n",
    "\n",
    "Para implementar un modelo de machine learning, el conjunto de datos se debe repartir en tres conjuntos:\n",
    "\n",
    "| Train | Development | Test |\n",
    "| --- | --- | --- |\n",
    "| se usa para entrenar | se usa para validar la | se usa para probar |\n",
    "| al modelo | arquitectura del modelo entrenado | al modelo entrenado |\n",
    "\n",
    "\n",
    "Tanto el conjunto de entrenamiento (train) como el de validacion o development (dev) se usan en el proceso de entrenamiento del algoritmo, la diferencia entre estos es que es con el conjunto de train con el que se 'aprenden' (se encuentran los pesos y biases optimos, es decir, los que minimizan a la funcion de costo) a los parametros, una vez que se tienen los parametros, el modelo realiza una evaluacion sobre el conjunto dev. \n",
    "\n",
    "\n",
    "Surge una primera pregunta: **¿Qué proporcion de datos se va a usar para cada conjunto?**\n",
    "\n",
    "1. El *conjunto de entrenamiento* tiene que ser el mas numeroso porque es con estos datos que el algortmo va a generar una funcion que 'aprenda' a relacionar a los datos que estamos interesados en correlacionar. \n",
    "\n",
    "2. El *conjunto de validacion* debe seguir un comportamiento similar al conjunto de entrenamiento, por lo que tienen que ser suficientes. 'suficiente' dependera de la cantidad de datos que tenga el conjunto original. \n",
    "\n",
    "3. El *conjunto de prueba* es mas pequeño, pues este se usara solo para probar al modelo, es decir, una vez entrenado este, queremos ver, con datos que nunca ha visto el modelo, qué tan bien aprendio. \n",
    "\n",
    "<img src=\"traindevtest.png\" width=600 height=600 align = \"midle\" >     \n",
    "\n",
    "\n",
    "Por lo general, los conjuntos de validacion y de prueba tienen la misma cantidad de muestras. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Si tenemos 100 muestras, 70 de ellas se usaran para entrenar al modelo, 15 para validarlo y el resto para probarlo. Supongamos que los datos corresponden a la altura de cien personas. Si realizamos el histograma de las 70 muestras de entrenamiento, observaremos que parecen seguir una distribucion gaussiana:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAc/ElEQVR4nO3deZxcdZ3u8c8ji8gmSwKyJAQUo+iVxQb0RpRFkDAIOuNVeDlOQCWCoIPiVVBGuLjhuHBFZsQAEURFBEVxhihBRURlCWEXHDCyhDBkYV8EAs/8UaehqPyqU5101enleb9e9eqz/M45318H6umzyzYRERGtXlR3ARERMTwlICIioigBERERRQmIiIgoSkBERERRAiIiIooSEDFsSDpV0r8M0bomSnpU0irV+KWSPjgU667WN0vStKFa3yC2+3lJiyX9d5fWf7OkXTtse4ekt3ajjhgeEhDRE9WXyROSHpH0oKQ/SDpU0nP/Ddo+1PbnOlzXgF9Mtu+yvbbtZ4ag9uMlfa9l/VNtn7Wy6x5kHROAo4BtbL+sMH9XSfML0zsOR9uvsX3pENRarCVGlgRE9NLbba8DbAGcCHwKOGOoNyJp1aFe5zCxBbDE9sK6C4mxIQERPWf7IdsXAu8Bpkl6LYCkMyV9vhoeJ+k/qr2N+yX9TtKLJJ0NTAR+Xh1C+qSkSZIs6QOS7gJ+3TStOSxeLukqSQ9J+pmkDaptLfPXbv9eiqS9gU8D76m2d301/7m/yqu6jpV0p6SFkr4r6aXVvP46pkm6qzo89Jl2vxtJL62WX1St79hq/W8FZgObVnWcuaK/f0n7SrquaU/uda39roZfIuksSQ9IuqX6XbfuFWwn6Ybqd3qupDUkrQXMaqr1UUmbrmi9UZ8ERNTG9lXAfGCXwuyjqnnjgY1pfEnb9vuAu2jsjaxt+1+blnkL8GrgbW02+U/A+4FNgaXAyR3U+Avgi8C51fa2LTQ7qPrsBmwFrA2c0tLmTcBkYA/gs5Je3WaT3wReWq3nLVXNB9u+BJgKLKjqOGh5tZdI2gGYCXwI2BD4NnChpBcXmh8HTKpq2RP4x0KbdwN7A1sCrwMOsv1YS61r216wIvVGvRIQUbcFwAaF6U8DmwBb2H7a9u+8/AeHHW/7MdtPtJl/tu2bqi+wfwHe3X8SeyW9F/i67Xm2HwWOAQ5o2Xv5f7afsH09cD2wTNBUtbwHOMb2I7bvAL4GvG8QtWxa7Rk896ERTv0OAb5t+0rbz1TnUZ4E3lBY17uBL9p+wPZ8yoF6su0Ftu8Hfg5sN4haY5hLQETdNgPuL0z/CnA7cLGkeZKO7mBddw9i/p3AasC4jqoc2KbV+prXvSqNPZ9+zVcdPU5jL6PVOGD1wro2G0QtC2yv1/wBLm+avwVwVEuATKj60GpTXvg7K/1+O+lXjFAJiKiNpB1pfPld3jqv+gv6KNtbAW8HPi5pj/7ZbVa5vD2MCU3DE2nspSwGHgPWbKprFRqHtjpd7wIaX7zN614K3Lec5VotrmpqXdc9g1zPQO4GvtASImvaPqfQ9l5g86bxCYU27eQx0aNAAiJ6TtK6kvYFfgh8z/aNhTb7SnqFJAEPA89UH2h88W61Apv+R0nbSFoTOAE4v7oM9r+ANST9naTVgGOB5mPy9wGTmi/JbXEO8DFJW0pam+fPWSwdTHFVLT8CviBpHUlbAB8HvjfwkoNyGnCopJ3VsFbV73UKbX8EHCNpfUmbAUcMYjv3ARv2n6yPkSkBEb30c0mP0Pgr9jPA14GD27TdGrgEeBT4I/DvTdfnfwk4tjpE8olBbP9s4Ewah0XWAD4KjauqgA8Dp9P4a/0xGifI+51X/VwiaW5hvTOrdV8G/BX4G/CRQdTV7CPV9ufR2LP6QbX+IWF7Do3zEKcAD9A4jHdQm+Yn0Pg9/JXGv8X5NM5XdLKdW2kE57zq3ylXMY1AyguDIqITkg4DDrD9lrprid7IHkREFEnaRNKU6j6MyTQuPb6g7rqid0brHacRsfJWp3GfxJbAgzTOGf17rRVFT+UQU0REFOUQU0REFI2qQ0zjxo3zpEmT6i4jImLEuOaaaxbbHl+aN6oCYtKkScyZM6fuMiIiRgxJd7abl0NMERFRlICIiIiiBERERBQlICIioigBERERRQmIiIgo6lpASJog6TfVu2xvlvTP1fQNJM2WdFv1c/02y0+r2twmaVq36oyIiLJu7kEsBY6y/WoarzM8XNI2wNHAr2xvDfyqGn+B6mXyxwE7AzsBx7ULkoiI6I6uBYTte23PrYYfAW6h8faw/YGzqmZnAe8oLP42YLbt+20/AMym8WL0iIjokZ7cSS1pErA9cCWwse17oREikjYqLLIZL3z/7XzavJdX0nRgOsDEiROHrugYlU77zrMsXtL7B1SO21AccnBO+cXI0vWAqF7B+GPgSNsPN94gufzFCtOK/1fbngHMAOjr68ujaWNAi5eYKVOf7vl2fz9rtZ5vM2JldfVPmur9vj8Gvm/7J9Xk+yRtUs3fBFhYWHQ+L3xB+uY0XgwfERE90s2rmAScAdxi++tNsy4E+q9Kmgb8rLD4L4G9qpelrw/sVU2LiIge6eYexBTgfcDukq6rPvsAJwJ7SroN2LMaR1KfpNMBbN8PfA64uvqcUE2LiIge6do5CNuXUz6XALBHof0c4INN4zOBmd2pLiIilieXVURERFECIiIiihIQERFRlICIiIiiBERERBQlICIioigBERERRQmIiIgoSkBERERRAiIiIooSEBERUZSAiIiIogREREQUJSAiIqKoJ++kjmhW13uhAa69wUyZWsumI0acBET0XF3vhQb4w5X5Tz6iU137v0XSTGBfYKHt11bTzgUmV03WAx60vV1h2TuAR4BngKW2+7pVZ0RElHXzz6kzgVOA7/ZPsP2e/mFJXwMeGmD53Wwv7lp1ERExoG6+cvQySZNK8yQJeDewe7e2HxERK6euq5h2Ae6zfVub+QYulnSNpOk9rCsiIip1nbE7EDhngPlTbC+QtBEwW9Ktti8rNawCZDrAxIkTh77SiIgxqud7EJJWBf4eOLddG9sLqp8LgQuAnQZoO8N2n+2+8ePHD3W5ERFjVh2HmN4K3Gp7fmmmpLUkrdM/DOwF3NTD+iIigi4GhKRzgD8CkyXNl/SBatYBtBxekrSppIuq0Y2ByyVdD1wF/KftX3SrzoiIKOvmVUwHtpl+UGHaAmCfangesG236oqIiM7kWUwREVGUgIiIiKIEREREFCUgIiKiKAERERFFCYiIiChKQERERFECIiIiihIQERFRlICIiIiiBERERBQlICIioigBERERRQmIiIgoSkBERERRAiIiIooSEBERUdTNV47OlLRQ0k1N046XdI+k66rPPm2W3VvSnyXdLunobtUYERHtdXMP4kxg78L0k2xvV30uap0paRXg34CpwDbAgZK26WKdERFR0LWAsH0ZcP8KLLoTcLvtebafAn4I7D+kxUVExHLVcQ7iCEk3VIeg1i/M3wy4u2l8fjWtSNJ0SXMkzVm0aNFQ1xoRMWb1OiC+Bbwc2A64F/haoY0K09xuhbZn2O6z3Td+/PihqTIiInobELbvs/2M7WeB02gcTmo1H5jQNL45sKAX9UVExPN6GhCSNmkafSdwU6HZ1cDWkraUtDpwAHBhL+qLiIjnrdqtFUs6B9gVGCdpPnAcsKuk7WgcMroD+FDVdlPgdNv72F4q6Qjgl8AqwEzbN3erzoiIKOtaQNg+sDD5jDZtFwD7NI1fBCxzCWxERPRO7qSOiIiiBERERBQlICIioigBERERRQmIiIgoSkBERERRAiIiIooSEBERUZSAiIiIogREREQUJSAiIqIoAREREUUJiIiIKEpAREREUQIiIiKKEhAREVGUgIiIiKKuBYSkmZIWSrqpadpXJN0q6QZJF0har82yd0i6UdJ1kuZ0q8aIiGivo4CQ9NoVWPeZwN4t02YDr7X9OuC/gGMGWH4329vZ7luBbUdExErqdA/iVElXSfpwu7/6W9m+DLi/ZdrFtpdWo1cAm3deakRE9FJHAWH7TcB7gQnAHEk/kLTnSm77/cCsdpsELpZ0jaTpA61E0nRJcyTNWbRo0UqWFBER/To+B2H7NuBY4FPAW4CTq/MJfz/YjUr6DLAU+H6bJlNs7wBMBQ6X9OYB6pphu8923/jx4wdbSkREtNHpOYjXSToJuAXYHXi77VdXwycNZoOSpgH7Au+17VIb2wuqnwuBC4CdBrONiIhYeZ3uQZwCzAW2tX247bnw3Bf5sZ1uTNLeNPZA9rP9eJs2a0lap38Y2Au4qdQ2IiK6Z9UO2+0DPGH7GQBJLwLWsP247bNLC0g6B9gVGCdpPnAcjauWXgzMlgRwhe1DJW0KnG57H2Bj4IJq/qrAD2z/YkU7GBERK6bTgLgEeCvwaDW+JnAx8L/bLWD7wMLkM9q0XUAjhLA9D9i2w7oiIqJLOg2INWz3hwO2H5W0Zpdqihh15l5rvvTVZ3q+3XEbikMOrueBCad951kWLymeZuyqOvs82nQaEI9J2qH/3IOk1wNPdK+siNHlb0/BlKlP93y7v5+1Ws+32W/xEo+5Po82nQbEkcB5khZU45sA7+lOSRERMRx0FBC2r5b0KmAyIOBW273/0yAiInqm0z0IgB2BSdUy20vC9ne7UlVERNSuo4CQdDbwcuA6oP9Mm4EERETEKNXpHkQfsE27O58jImL06fRasJuAl3WzkIiIGF463YMYB/xJ0lXAk/0Tbe/XlaoiIqJ2nQbE8d0sIiIihp9OL3P9raQtgK1tX1LdRb1Kd0uLiJVV1x3cANfeYKZMrWXTMUQ6vYrpEGA6sAGNq5k2A04F9uheaRGxsuq6gxvgD1cO5ir6GI46PUl9ODAFeBiee3nQRt0qKiIi6tdpQDxp+6n+EUmr0rgPIiIiRqlOA+K3kj4NvKR6F/V5wM+7V1ZERNSt04A4GlgE3Ah8CLiIQbxJLiIiRp5Or2J6Fjit+kRExBjQ0R6EpL9Kmtf66WC5mZIWSrqpadoGkmZLuq36uX6bZadVbW6TNK3zLkVExFDo9BBTH42nue4I7AKcDHyvg+XOBPZumXY08CvbWwO/qsZfQNIGNN5hvTOwE3BcuyCJiIju6CggbC9p+txj+/8Du3ew3GXA/S2T9wfOqobPAt5RWPRtwGzb99t+AJjNskETERFd1OmNcjs0jb6Ixh7FOiu4zY1t3wtg+15JpfspNgPubhqfX00r1Tadxk18TJw4cQVLGpvqemdw7rCNGBk6vdXxa03DS4E7gHcPeTXPU2Fa8ZvM9gxgBkBfX1/uzRiEut4ZnDtsI0aGTq9i2m0It3mfpE2qvYdNgIWFNvOBXZvGNwcuHcIaIiJiOTo9xPTxgebb/vogtnkhMA04sfr5s0KbXwJfbDoxvRdwzCC2ERERK2kwVzEdRuM8wGbAocA2NM5DtD0XIekc4I/AZEnzJX2ARjDsKek2YM9qHEl9kk4HsH0/8Dng6upzQjUtIiJ6ZDAvDNrB9iMAko4HzrP9wYEWsn1gm1nLPAXW9hzgg03jM4GZHdYXERFDrNM9iInAU03jTwGThryaiIgYNjrdgzgbuErSBTSuJnon8N2uVRUREbXr9CqmL0iaReMuaoCDbV/bvbIiIqJunR5iAlgTeNj2N4D5krbsUk0RETEMdPqwvuOAT/H8paar0dmzmCIiYoTqdA/incB+wGMAthew4o/aiIiIEaDTgHjKtqkedyFpre6VFBERw0GnAfEjSd8G1pN0CHAJeXlQRMSottyrmCQJOBd4FfAwMBn4rO3ZXa4tIiJqtNyAsG1JP7X9ehrvZYiIiDGg00NMV0jasauVRETEsNLpndS7AYdKuoPGlUyisXPxum4VFhER9RowICRNtH0XkPd/RUSMMcvbg/gpjae43inpx7b/oRdFRURE/ZZ3DqL51Z9bdbOQiIgYXpYXEG4zHBERo9zyDjFtK+lhGnsSL6mG4fmT1Ot2tbqIiKjNgHsQtlexva7tdWyvWg33j69QOEiaLOm6ps/Dko5sabOrpIea2nx2RbYVERErrtPLXIeM7T8D2wFIWgW4B7ig0PR3tvftZW0REfG8wbwPohv2AP5i+86a64iIiBZ1B8QBwDlt5r1R0vWSZkl6TbsVSJouaY6kOYsWLepOlRERY1BtASFpdRrvmDivMHsusIXtbYFv0rgfo8j2DNt9tvvGjx/fnWIjIsagOvcgpgJzbd/XOsP2w7YfrYYvAlaTNK7XBUZEjGV1BsSBtDm8JOll1WPGkbQTjTqX9LC2iIgxr+dXMQFIWhPYE/hQ07RDAWyfCrwLOEzSUuAJ4IDqjXYREdEjtQSE7ceBDVumndo0fApwSq/rqsNp33mWxUvqyb5rbzBT8hjGiGijloCI5y1eYqZMfbqWbf/hyvzzR0R7dV/mGhERw1QCIiIiihIQERFRlICIiIiiBERERBQlICIioigBERERRQmIiIgoSkBERERRAiIiIooSEBERUZSAiIiIogREREQUJSAiIqIoAREREUUJiIiIKKotICTdIelGSddJmlOYL0knS7pd0g2SdqijzoiIsaruV4rtZntxm3lTga2rz87At6qfERHRA8P5ENP+wHfdcAWwnqRN6i4qImKsqDMgDFws6RpJ0wvzNwPubhqfX017AUnTJc2RNGfRokVdKjUiYuypMyCm2N6BxqGkwyW9uWW+Cst4mQn2DNt9tvvGjx/fjTojIsak2gLC9oLq50LgAmCnlibzgQlN45sDC3pTXURE1BIQktaStE7/MLAXcFNLswuBf6quZnoD8JDte3tcakTEmFXXVUwbAxdI6q/hB7Z/IelQANunAhcB+wC3A48DB9dUa0TEmFRLQNieB2xbmH5q07CBw3tZV0REPG84X+YaERE1SkBERERRAiIiIooSEBERUVT3s5giIobU3GvNl776TC3bHrehOOTg0fN3dwIiIkaVvz0FU6Y+Xcu2fz9rtVq22y2jJ+oiImJIJSAiIqIoAREREUUJiIiIKEpAREREUQIiIiKKEhAREVGUgIiIiKIEREREFOVO6spp33mWxUuWeeV11117g5kyteebjYguqOsxH916xEcCorJ4iWu5Pf8PV+afIGK0qOsxH916xEfPDzFJmiDpN5JukXSzpH8utNlV0kOSrqs+n+11nRERY10df74uBY6yPVfSOsA1kmbb/lNLu9/Z3reG+iIighr2IGzfa3tuNfwIcAuwWa/riIiIgdV6FZOkScD2wJWF2W+UdL2kWZJeM8A6pkuaI2nOokWLulRpRMTYU1tASFob+DFwpO2HW2bPBbawvS3wTeCn7dZje4btPtt948eP717BERFjTC0BIWk1GuHwfds/aZ1v+2Hbj1bDFwGrSRrX4zIjIsa0Oq5iEnAGcIvtr7dp87KqHZJ2olHnkt5VGRERdVzFNAV4H3CjpOuqaZ8GJgLYPhV4F3CYpKXAE8ABtnt/F1tExBjW84CwfTmg5bQ5BTilNxVFRERJnsUUERFFCYiIiChKQERERFECIiIiihIQERFRlICIiIiiBERERBQlICIioigBERERRQmIiIgoSkBERERRAiIiIooSEBERUZSAiIiIogREREQUJSAiIqIoAREREUW1BISkvSX9WdLtko4uzH+xpHOr+VdKmtT7KiMixraeB4SkVYB/A6YC2wAHStqmpdkHgAdsvwI4Cfhyb6uMiIg69iB2Am63Pc/2U8APgf1b2uwPnFUNnw/sIWnA91hHRMTQku3eblB6F7C37Q9W4+8DdrZ9RFObm6o286vxv1RtFhfWNx2YXo1OBv7c5S60GgcsU9cINpr6M5r6AunPcDdS+7OF7fGlGav2uhKgtCfQmlKdtGlMtGcAM1a2qBUlaY7tvrq2P9RGU39GU18g/RnuRlt/oJ5DTPOBCU3jmwML2rWRtCrwUuD+nlQXERFAPQFxNbC1pC0lrQ4cAFzY0uZCYFo1/C7g1+71sbCIiDGu54eYbC+VdATwS2AVYKbtmyWdAMyxfSFwBnC2pNtp7Dkc0Os6B6G2w1tdMpr6M5r6AunPcDfa+tP7k9QRETEy5E7qiIgoSkBERERRAmIQJK0n6XxJt0q6RdIbm+Z9QpIljauzxsFo1x9JH6kehXKzpH+tu85OlfojaTtJV0i6TtIcSTvVXWcnJE2uau7/PCzpSEkbSJot6bbq5/p119qJAfrzlerf6wZJF0har+5al6ddX5rmj7jvgnZyDmIQJJ0F/M726dUVWGvaflDSBOB04FXA60s39A1Hpf4A2wOfAf7O9pOSNrK9sNZCO9SmPz8CTrI9S9I+wCdt71pnnYNVPZ7mHmBn4HDgftsnVs8xW9/2p2otcJBa+jOZxlWKSyV9GWAk9ae5L7bvHKnfBe1kD6JDktYF3kzjCitsP2X7wWr2ScAnaXMz33A0QH8OA060/WQ1faSEQ7v+GFi3avZSlr3nZiTYA/iL7Tt54WNozgLeUVtVK+65/ti+2PbSavoVNO6LGkma/21gBH4XDCQB0bmtgEXAdyRdK+l0SWtJ2g+4x/b1Ndc3WMX+AK8EdqmeovtbSTvWW2bH2vXnSOArku4GvgocU2eRK+gA4JxqeGPb9wJUPzeqraoV19yfZu8HZvW4lpX1XF9G8HdBWwmIzq0K7AB8y/b2wGPA8TQOx3y2xrpWVKk/R1fT1wfeAPxf4Ecj5EGJ7fpzGPAx2xOAj1HtYYwU1aGy/YDz6q5lKLTrj6TPAEuB79dR14po7oukNRm53wVtJSA6Nx+Yb/vKavx8Gl9IWwLXS7qDxu7xXEkvq6fEQWnXn/nAT9xwFfAsjYeQDXft+jMN+Ek17TwaTxMeSaYCc23fV43fJ2kTgOrniDgE2KS1P0iaBuwLvHeEPTGhuS8vZ+R+F7SVgOiQ7f8G7pY0uZq0B43/ODayPcn2JBpfUjtUbYe1Nv35E/BTYHcASa8EVmcEPKFygP4sAN5STdsduK2G8lbGgbzwcEzzY2imAT/reUUr5wX9kbQ38ClgP9uP11bVinmuL7ZvHKnfBQPJVUyDIGk7GlcorA7MAw62/UDT/DuAvpFy5UKpPzQOzcwEtgOeAj5h+9e1FTkIbfrzGuAbNA5B/Q34sO1raityEKrDFncDW9l+qJq2IY0rsyYCdwH/x/aIeJBlm/7cDrwYWFI1u8L2oTWV2LFSX1rm38EI+i5oJwERERFFOcQUERFFCYiIiChKQERERFECIiIiihIQERFRlICIMU3Soy3jB0k6ZTnL7Fc9KG+gNrtK+o82846sLpNst+z5krYaaP0t7f+XpDM7bR/RqQRExCDZvtD2iSuxiiNpPGl2GZJeA6xie94g6rkR2FzSxJWoKWIZCYiINiSNl/RjSVdXnynV9Of2MiS9vHrfxNWSTmjZI1lbz7+f4vtq+CiwKfAbSb8pbPa9NN0dLelRSV+WdI2kSyTtJOlSSfOqh8P1+znD+93tMQIlIGKse0nzy1+AE5rmfYPGuyR2BP6Bxl3arb4BfKNq0/oo8e1p7C1sQ+Nps1Nsn1y12832boX1TQGa7/ReC7jU9uuBR4DPA3sC72ypdQ6wSycdjujUqnUXEFGzJ2xv1z8i6SCgrxp9K7BN08Ns15W0Tsvyb+T5dzL8gMYjxftdZXt+td7rgEnA5cupZxMajy3v9xTwi2r4RuBJ209LurFaX7+FNPZMIoZMAiKivRcBb7T9RPPEQTz9/Mmm4Wfo7P+3J4A1msafbnrC6bP967T9rKTm9a1RLRsxZHKIKaK9i4Ej+keqhwG2uoLG4Sfo/BzAI0Drnki/W4BXdFpgk1cCN63AchFtJSAi2vso0CfpBkl/AkpPGT0S+Likq2gcHlrmyZ4FM4BZbU5S/yew6wrUulu1bMSQydNcI1ZCdT/DE7Yt6QDgQNv7r8T6XgL8hsYJ7Wc6XObFwG+BNzW93zlipSUgIlaCpF2AUwABDwLvt337Sq7zbcAttu/qsP3WwGa2L12Z7Ua0SkBERERRzkFERERRAiIiIooSEBERUZSAiIiIogREREQU/Q/YaoEehOc/3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "df=pd.read_csv('weight-height.csv')\n",
    "df_1 = df[:100]\n",
    "df_2 = df[:15]\n",
    "# Histogram of the height\n",
    "df_1.Height.plot(kind='hist',color='cornflowerblue',edgecolor='b', alpha=0.4)\n",
    "plt.title('Distribution of Height')\n",
    "plt.xlabel('Height (m)')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "¿Qué pasa si realizamos el histograma de las 15 muestras de validacion?, dificilmente, al tratarse de tan pocos datos, se lograra ver una distribucion gaussiana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of the height\n",
    "df_2.Height.plot(kind='hist',color='rosybrown',edgecolor='b', alpha=0.5)\n",
    "plt.title('Distribution of Height')\n",
    "plt.xlabel('Height (m)')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Es por eso que la cantidad de muestras para cada conjunto depende del numero de muestras que se tenga en total, cuidando siempre que el conjunto de validacion sea suficiente para que tenga un comportamiento parecido al del conjunto de entrenamiento. \n",
    "\n",
    "Una segunda pregunta podria ser: **¿De dónde provienen los conjuntos de datos?**\n",
    "\n",
    "Dado que estamos interesados en que un modelo aprenda, queremos que este generalice bien. Un ejemplo, si doy pares de numeros: n y m ,con n y m entre 0 y 100, y quiero que el modelo aprenda a multiplicar esos pares de numeros, nos gustaria que tambien aprenda a multiplicar pares de numeros mas grandes que 100, es decir, a partir de la informacion que le dimos queremos que esta aprenda a generalizar la operacion de producto binario. \n",
    "\n",
    "*Una practica recomendada es que los conjuntos de validacion y de prueba provengan de la misma distribucion*, y que esta sea diferente a la distribucion del conjunto de entrenamiento. De esta manera, podemos saber si el modelo que aprendio con el conjunto train es capaz de generalizar lo aprendido, es decir, si lo hara bien para el conjunto dev. \n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    ">> ### Bias and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "[A high-bias, low-variance introduction to Machine Learning for physicists](https://arxiv.org/abs/1803.08823) pp 10-13\n",
    "\n",
    "Suponiendo que se desea separar las *x* de los *o* podemos hacer las siguientes observaciones:\n",
    "\n",
    "<img src=\"bias.png\" width=600 height=600 align = \"midle\" >     \n",
    "\n",
    "\n",
    "1. Izquierda: Si ajustas una línea recta a los datos, tal vez conseguirás una regresión logística ajustada a eso.\n",
    "Esto no es un muy buen ajuste a los datos.\n",
    "Y esto tiene un bias elevado.\n",
    "\n",
    "\n",
    "2. Derecha: si ajustas un clasificador increíblemente complejo, tal vez una red neuronal profunda, o una red neuronal con muchas unidades ocultas, tal vez puedas ajustar perfectamente los datos, pero eso tampoco parece ser un gran ajuste.\n",
    "Es un clasificador de alta varianza y esto ocasiona un sobre ajuste (**overfitting**) a los datos.\n",
    "\n",
    "\n",
    "3. Centro: Podría haber algún clasificador en el medio, con un nivel medio de complejidad, que tal vez se ajusta correctamente. \n",
    "\n",
    "\n",
    "En un ejemplo 2D como este, con solo dos características, X-1 y X-2, puedes trazar los datos y visualizar el sesgo y la varianza. En problemas de alta dimensión, no puedes trazar los datos y visualizar el límite de la división.\n",
    "\n",
    "\n",
    "En cambio, hay un par de métricas para tratar de entender el sesgo y la varianza: \n",
    "\n",
    "\n",
    "\n",
    "    el error del conjunto de entrenamiento (*train error*) y \n",
    "\n",
    "\n",
    "    el error en el conjunto de desarrollo (*error dev*). \n",
    "\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Supongamos que tenemos los siguientes resultados:\n",
    "\n",
    "\n",
    "\n",
    "| error train | error dev | diagnosis |\n",
    "| --- | --- | --- |\n",
    "| 1% | 11% | High variance |\n",
    "| 15% | 16% | High bias |\n",
    "| 15% | 30% | High Bias & variance |\n",
    "| 0.5% | 1% | loss Bias & variance |\n",
    "\n",
    "1. En el ejemplo del primer renglon, lo estás haciendo muy bien en el conjunto de entrenamiento, pero estás haciéndolo relativamente mal en el conjunto de desarrollo. Así que este algoritmo parece que podría haber sobre ajustado (*overfitting*) el conjunto de entrenamiento pues no está generalizando correctamente al conjunto de validación. \n",
    "\n",
    "Si tienes un ejemplo como este, decimos que esto tiene una varianza alta.\n",
    "\n",
    "\n",
    "2. Ahora, digamos que mides tu error en el conjunto de entrenamiento y en el de desarrollo, y obtienes un resultado diferente (renglon dos). Digamos que el error de entrenamiento es del 15% y tu error en el conjunto de desarrollo es 16%.\n",
    "En este caso, suponiendo que los humanos logran un error de aproximadamente 0%, entonces parece que el algoritmo ni siquiera está funcionando muy bien en el conjunto de entrenamiento.\n",
    "\n",
    "Este algoritmo tiene un alto sesgo. \n",
    "\n",
    "Pero en contraste, esto se generaliza bien a un nivel razonable para el conjunto de desarrollo, mientras que el rendimiento en el conjunto de desarrollo es solo un 1% peor que el rendimiento en el conjunto de entrenamiento.\n",
    "\n",
    "\n",
    "3. En el renglon tres tienes un 15% de error de entrenamiento, así que hay un sesgo bastante alto, pero cuando evalúas el conjunto de dev, lo hace aún peor, tal vez lo hace el 30%.\n",
    "\n",
    "En este caso, diagnosticaría que este algoritmo tiene un alto sesgo, porque no lo está haciendo tan bien en el conjunto de entrenamiento, y además tiene alta varianza.\n",
    "\n",
    "\n",
    "4. Y un último ejemplo, si tiene un error de conjunto de entrenamiento 0.5%, y 1% de error en desarrollo, se tiene un sesgo bajo y una varianza baja.\n",
    "\n",
    "\n",
    "\n",
    "Este análisis se basa en el supuesto de que el rendimiento a nivel humano tiene casi un 0% de error o, más en general, que el error óptimo (error de Bayes) es casi el 0%.\n",
    "\n",
    "Si el error óptimo o el error de Bayes fueran mucho más altos, digamos, si fuera del 15%, entonces si nos fijamos en este clasificador, 15% es en realidad perfectamente razonable para el conjunto de entrenamiento y tú\n",
    "no lo verías como un alto sesgo. \n",
    "\n",
    "Así que el caso de cómo analizar el sesgo y la varianza, cuando ningún clasificador funciona muy bien, por ejemplo, si tienes imágenes borrosas, de modo que incluso un sistema humano o simplemente ningún sistema podría hacerlo muy bien, entonces tal vez el error de Bayes es mucho mayor, y hay algunos detalles de cómo cambiará este análisis.\n",
    "\n",
    "___\n",
    "\n",
    "**Resumen**\n",
    "\n",
    "\n",
    "1. Observar *error train* (¿el algoritmo se ajusta bien con los datos de entrenamiento?), esto indica si hay un problema de sesgo. \n",
    "\n",
    "\n",
    "2. Observar *error dev* (¿generaliza bien desde el conjunto de entrenamiento al conjunto de validacion?) indica si hay un problema con la varianza. \n",
    "\n",
    "\n",
    "Todo esto bajo el supuesto de que el error de Bayes es bastante pequeño y que los conjuntos de entrenamiento y desarrollo se extraen de la misma distribución.\n",
    "\n",
    "\n",
    "Dependiendo de si tu algoritmo sufre de sesgo o varianza, hay diferentes cosas que puedes probar para arreglarlo.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    ">> ### Basic recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    " Después de haber entrenado un modelo inicial, nos preguntamos:\n",
    "\n",
    "1. *¿El algoritmo tiene un alto sesgo?*\n",
    "\n",
    "Para tratar de evaluar si hay un alto sesgo, debes observar el rendimiento sobre los datos de entrenamiento.\n",
    "Si tiene un alto sesgo, ni siquiera se ajusta bien el conjunto de entrenamiento.\n",
    "\n",
    "Algunas cosas que podrías intentar serían:\n",
    "\n",
    "\n",
    "    1.1 intentar escoger una red más grande: agregar más capas o más unidades por capa\n",
    "\n",
    "\n",
    "    1.2 entrenarla por más tiempo.\n",
    "    \n",
    "\n",
    "    1.3 probar algunos algoritmos de optimización más avanzados.\n",
    "    \n",
    "\n",
    "Usar una red más grande casi siempre ayuda. Y entrenar por más tiempo no siempre ayuda, pero no hace daño.\n",
    "\n",
    "\n",
    "2. Una vez que reduzcas el sesgo a cantidades aceptables, pregunta, *¿Hay algún problema de varianza?*\n",
    "\n",
    "Para evaluar eso observamos el rendimiento sobre el conjunto de desarrollo.\n",
    "\n",
    "¿Eres capaz de generalizar desde un conjunto de entrenamiento con buen rendimiento para tener un buen rendimiento en el conjunto de desarrollo?\n",
    "\n",
    "Si tienes alta varianza, la mejor manera de resolver el problema es:\n",
    "\n",
    "    2.1 obtener más datos.\n",
    "    \n",
    "\n",
    "    2.2 regularización\n",
    " \n",
    " \n",
    "<font color='rosybrown'> \n",
    "    \n",
    " NOTAS:\n",
    " \n",
    "\n",
    "* Conseguir una red más grande casi siempre solo reduce tu sesgo sin dañar necesariamente su varianza, siempre y cuando se regularice adecuadamente.\n",
    "\n",
    "\n",
    "* Obtener mas datos casi siempre reduce tu varianza y no daña mucho tu sesgo.\n",
    "\n",
    "\n",
    "* El costo principal de entrenar una red neuronal demasiado grande es solo el tiempo computacional, siempre que estés regularizando.\n",
    "\n",
    "\n",
    "* Pero si puedes encontrar una arquitectura de red neuronal más apropiada, a veces eso también puede reducir tu problema de varianza, así como reducir tu problema de sesgo. \n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    "> ## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "La regularización, es una técnica muy útil para reducir la varianza.\n",
    "\n",
    "Recordemos que se usa una métrica para observar cómo va el entrenamiento en un modelo. La función de costo compara la predicción hecha por la red con el valor real al cual se quiere llegar, el objetivo es minimizar esta función, pues lo que se estaria haciendo es que la predicción y el valor real sean lo mas parecido posible. \n",
    "\n",
    "\n",
    "La función de costo se denota con J, mientras que la función de perdida se denota con L.\n",
    "\n",
    "\n",
    "$$J(w, b) = \\dfrac{1}{m}\\Sigma_{i=1}^{m} L(y^{(i)}, \\hat{y}^{(i)})$$\n",
    "\n",
    "donde $w$ y $b$ son los parámetros que se deben encontrar de tal manera que se minimice a la función J.\n",
    "\n",
    "Se tiene que\n",
    "\n",
    "$$w \\epsilon \\Re^{n_x}, b \\epsilon \\Re  $$\n",
    "\n",
    "si $w$ y $b$ son los parámetros en la capa $l$, etonces $n_x$ es el número de nodos de la capa $l-1$ y $m$ es el número de muestras. \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"Red_2.png\" width=1000 height=1000 align = \"midle\" >     \n",
    "\n",
    "<font size=2>\n",
    "    \n",
    "La imagen fue realizada por Luis Fermin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    ">> ### L2 regularization (weight decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "Para agregar regularización se agrega un siguiente término a la función $J$:\n",
    "\n",
    "$$J(w, b) = \\dfrac{1}{m}\\Sigma_{i=1}^{m} L(y^{(i)}, \\hat{y}^{(i)}) + \\dfrac{\\lambda}{2m}||w||^2_{2}  $$\n",
    "\n",
    "donde $||w||^2_{2} = w^T*w = \\Sigma_{j=1}^{n_x}w_j^{2}$\n",
    "\n",
    "\n",
    "$\\lambda$ se denomina parámetro de regularización\n",
    "\n",
    "El término adicional penaliza a las matrices de peso por ser demasiado grandes. \n",
    "\n",
    "\n",
    " ¿por qué regulariza solo el parámetro w?, ¿Por qué no añadimos algo aquí también sobre b?\n",
    " \n",
    " \n",
    "Si miras tus parámetros, w suele ser una dimensión bastante alta, especialmente con un problema de alta varianza.\n",
    "Tal vez w solo tiene muchos parámetros, entonces no está ajustando todos los parámetros bien, mientras que b es solo un número. Así que casi todos los parámetros están en w en lugar de b.\n",
    "Y si agrega este último término, en la práctica, no hará mucha diferencia porque b es solo un parámetro sobre un número muy grande de parámetros.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<font color='rosybrown'>\n",
    "NOTA:\n",
    "\n",
    "lambda es un hiper-parámetro, es decir, es un parámetro que hay que ajustar.\n",
    "<font color='black'>\n",
    "\n",
    "\n",
    "Generalizando la ecuación anterior para redes neuronales:\n",
    "\n",
    "$$J(w^{[1]}, b^{[1]}, ..., w^{[L]}, b^{[L]}) = \\dfrac{1}{m}\\Sigma_{i=1}^{m} L(y^{(i)}, \\hat{y}^{(i)}) + \\dfrac{\\lambda}{2m}||w||^2_{F}$$\n",
    "\n",
    "donde $||w||^2_{F}$ es la norma de Frobenius y L es el número de capas en la red (el número de capas ocultas mas la capa de salida). \n",
    "\n",
    "Recordemos que la actualización de los parámetros esta dada por:\n",
    "\n",
    "$$w^{[l]} = w^{[l]} - \\alpha \\dfrac{\\partial J}{\\partial w^{[l]}}$$\n",
    "\n",
    "dado que ahora la función de costo tiene un término mas, la derivada es:\n",
    "\n",
    "$$\\dfrac{\\partial J}{\\partial w^{[l]}} = x + \\dfrac{\\lambda}{m}w^{[l]} $$\n",
    "\n",
    "donde x es la derivada de la función de costo sin agregar el término de regularización.\n",
    "\n",
    "La actualización de los parámetros será:\n",
    "\n",
    "$$w^{[l]} = w^{[l]} - \\alpha ( x + \\dfrac{\\lambda}{m}w^{[l]})$$\n",
    "\n",
    "\n",
    "esto es:\n",
    "\n",
    "$$w^{[l]} = (1-\\dfrac{\\alpha \\lambda}{m})w^{[l]} - \\alpha x$$\n",
    "\n",
    "observa que el termino $(1-\\dfrac{\\alpha \\lambda}{m})$ es menor que 1 por lo que la matriz de pesos $w^{[l]}$ se esta multiplicando por un término pequeño. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    ">> ### L1 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "La funcion de costo J, se modifica por:\n",
    "\n",
    "\n",
    "$$J(w, b) = \\dfrac{1}{m}\\Sigma_{i=1}^{m} L(y^{(i)}, \\hat{y}^{(i)}) + \\dfrac{\\lambda}{2m}|w|_1  $$\n",
    "\n",
    "donde $|w|_1  = \\Sigma_{j=1}^{n_x}|w_j|$\n",
    "\n",
    "\n",
    "\n",
    "Si usas la regularización L1, entonces w terminará siendo escaso, lo que eso significa es que el vector w tendrá muchos ceros.\n",
    "\n",
    "\n",
    "Algunas personas dicen que esto puede ayudar a comprimir el modelo, porque el conjunto de parámetros es cero, y necesita menos memoria para almacenar el modelo.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "**¿Por qué la regularizacion disminuye el overfitting?**\n",
    "    \n",
    "1. Si la regularización hace que $\\lambda$ sea realmente, muy grande, los modelos estarán incentivados a establecer matrices de peso W que estén razonablemente cerca de cero.\n",
    "\n",
    "Una parte de la intuición es que tal vez establece que el peso sea tan cercano a cero para una gran cantidad de unidades ocultas (que es básicamente cero) y el impacto de estas unidades ocultas es nulo.\n",
    "\n",
    "Si ese es el caso,entonces esta red neuronal mucho más simplificada se convierte en una red neuronal mucho más pequeña.\n",
    "\n",
    "En la práctica esto no es en realidad lo que sucede.\n",
    "\n",
    "La intuición de reducir completamente a cero un grupo de unidades ocultas no es del todo correcta.\n",
    "\n",
    "Resulta que lo que realmente sucede es que todavía usarás todas las unidades ocultas, pero cada una de ellos tendría un efecto mucho menor.\n",
    "\n",
    "Terminas con una red más simple y será como si tuvieras una red más pequeña que, por lo tanto, es menos propensa al sobreajuste.\n",
    "\n",
    "2. Por otro lado para varias de las funciones f(x) de activacion que se usan en ML se tiene que para valores pequeños de x, f(x) se aproxima bien a una recta (por ejemplo sigmoid o tanh). \n",
    "\n",
    "<img src=\"sigmoid.png\" width=450 height=450 align = \"left\" >     \n",
    "<img src=\"tanh.png\" width=500 height=500 align = \"right\" >     \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Si $\\lambda$ es grande, entonces w es pequeño y por tanto z ($x*w+b$) sera un numero pequeño. \n",
    "\n",
    "\n",
    "Es como si cada capa fuera aproximadamente lineal.\n",
    "Y por tanto, no es capaz de ajustarse a un problema de decisión muy complicado, no hay sobreajuste.\n",
    "\n",
    "\n",
    "Y así, toda tu red neuronal estará computando algo no muy lejos de una gran función lineal que por lo tanto es una función bastante simple en lugar de una función altamente no lineal altamente compleja.\n",
    "Y también es mucho menos capaz de sobre ajustarse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    ">> ### Dropout regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font size=4>\n",
    "    \n",
    " Otra técnica de regularización es el dropout.\n",
    " \n",
    "\n",
    "Con dropout, lo que vamos a hacer es ir a través de cada una de las capas de la red se asaigna cierta probabilidad de eliminar un nodo de la red neuronal.\n",
    "\n",
    "\n",
    "<img src=\"dropout.gif\" width=600 height=600 align = \"midle\" >     \n",
    "\n",
    "\n",
    "Digamos que para la segunda capa oculta, vamos a -para cada nodo- lanzar una moneda y tendremos una probabilidad de 0.5 de mantener cada nodo y 0.5 de eliminarlo.\n",
    "\n",
    "Después de lanzar las monedas, tal vez decidiremos eliminar esos nodos, entonces lo que harás es remover también todas las conexiones que entran y salen de ese nodo.\n",
    "\n",
    "Así que terminas con una red mucho más pequeña. \n",
    "Y luego en diversos ejemplos, vuelves a lanzar monedas y mantendrás un conjunto de nodos diferente y abandonarás o eliminarás otros distintos.\n",
    "Y así, por cada ejemplar de entrenamiento, realizarías el entrenamiento sobre alguna de estas redes reducidas.\n",
    "\n",
    "\n",
    "\n",
    "Entonces, no es que para un ejemplo debas mantener a cero las mismas unidades ocultas, es que, en la iteración uno de descenso por gradiente puedes poner a cero algunas unidades ocultas.\n",
    "Y en la segunda iteración del descenso por gradiente donde vas a través del conjunto de entrenamiento la segunda vez, tal vez puedas poner a cero un patrón diferente de unidades ocultas. \n",
    "\n",
    "\n",
    "Ahora, habiendo entrenado el algoritmo, en el momento de la prueba, esto es lo que harías.\n",
    "\n",
    "En el momento de la prueba, le das una x o la que desea hacer una predicción.\n",
    "Y usando nuestra notación estándar:\n",
    "\n",
    "$x = a^0$,\n",
    "\n",
    "las activaciones de la capa cero para denotar solo el ejemplo de prueba x.\n",
    "\n",
    "Entonces, lo que vamos a hacer es no usar dropout en el momento de la prueba, en particular, que será\n",
    "\n",
    "$z ^ 1 = w ^ 1.a ^ 0 + b ^ 1$\n",
    "\n",
    "$a ^ 1 = g ^ 1 (z ^ 1)$\n",
    "\n",
    "$z ^ 2 = w ^ 2.a ^ 1 + b ^ 2$\n",
    "\n",
    "$a ^ 2 = ...$\n",
    "\n",
    "Hasta que llegues a la última capa y hagas una predicción $y^$.\n",
    "\n",
    "Pero nota que en tiempo de prueba que no estás usando dropout explícitamente y no estás lanzando monedas al azar, no estás lanzando monedas para decidir qué unidades ocultas eliminar.\n",
    "Y eso es porque cuando estás haciendo predicciones en el momento de la prueba, no quieres que tu salida sea aleatoria.\n",
    "Si está implementando el dropout en el momento de la prueba, Eso solo añade ruido a tus predicciones.\n",
    "En teoría, una cosa que podrías hacer es ejecutar un proceso de predicción muchas veces, con diferentes unidades ocultas retiradas al azar y promediar.\n",
    "Pero eso es computacionalmente ineficiente y le dará aproximadamente el mismo resultado.\n",
    "El efecto de eso fue asegurar que incluso cuando no se implementa dropout en el momento de prueba para escalar,\n",
    "El valor esperado de estas activaciones no cambia.\n",
    "Por lo tanto, no es necesario agregar un parámetro raro de escalado adicional en el tiempo de prueba.\n",
    "\n",
    "\n",
    "**¿Porqué funciona?**\n",
    "\n",
    "\n",
    "Es como si en cada iteración estuvieras trabajando con una red neuronal más pequeña, y así, el uso de una red neuronal más pequeña parece que debería tener un efecto de regularización.\n",
    "\n",
    "\n",
    "Una segunda intuición que es, echémosle un vistazo a esto desde la perspectiva de una sola unidad. \n",
    "\n",
    "Ahora, para que esta unidad haga su trabajo en cuanto a las entradas, necesita generar algún resultado significativo.\n",
    "Ahora con dropout, las entradas pueden ser eliminadas al azar. A veces estas dos unidades serán eliminadas,\n",
    "a veces una unidad diferente será eliminada.\n",
    "Entonces, lo que esto significa es que esta unidad, no se puede confiar en ninguna característica porque cualquier característica podría desaparecer al azar o cualquiera de sus entradas podría desaparecer al azar.\n",
    "\n",
    "\n",
    "El efecto de implementar dropout es que se reducen los pesos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    ">> ### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "\n",
    "Obtener más datos de entrenamiento puede ayudar, pero obtener más los datos de capacitación pueden ser costosos y, a veces, simplemente no puede obtener más datos.\n",
    "\n",
    "Lo que puedes hacer es aumentar tu conjunto de entrenamiento tomando una imagen por ejemplo y voltearla horizontalmente.\n",
    "\n",
    "  <img src=\"dataaug.png\" width=600 height=600 align = \"midle\" >     \n",
    "\n",
    "\n",
    "Así que ahora, en lugar de este único ejemplo en tu conjunto de entrenamiento, puedes agregar esto a tu ejemplo de entrenamiento.\n",
    "\n",
    "Así que al voltear las imágenes horizontalmente, podría duplicar el tamaño de su conjunto de entrenamiento.\n",
    "Debido a que el conjunto de entrenamiento ahora es un poco redundante, esto no es tan bueno como si tuviera un conjunto adicional de nuevos ejemplos independientes.\n",
    "\n",
    "También puedes voltear horizontalmente, tomar secciones aleatorias de la imagen, rotar y hacer una especie de zoom aleatorio en la imagen, conservando que bajo las transformaciones todavía parezca un gato.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='rosybrown'>\n",
    "    \n",
    ">> ### Early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "   <img src=\"early.png\" width=600 height=600 align = \"midle\" >     \n",
    "\n",
    "    \n",
    "Si se encuentra que el error de su conjunto de validación se reduce por un tiempo, y después aumenta a partir de un punto.\n",
    "Entonces, se detiene el entrenamiento en ese punto.\n",
    "\n",
    "Parece que tu red neuronal estaba haciendo lo mejor posible en esa iteración, por lo que solo queremos dejar de operar en su red neuronal a mitad de camino y tomar cualquier valor alcanzado para el error en el conjunto de desarrollo.\n",
    "\n",
    "\n",
    "¿por qué funciona esto?\n",
    "Bueno, cuando no has corrido muchas iteraciones para la red neuronal todavía sus parámetros w estarán cerca de cero.\n",
    "\n",
    "\n",
    "Porque con la inicialización aleatoria probablemente inicialice w a pequeño aleatorio los valores, así que antes de entrenar por mucho tiempo, w todavía es bastante pequeño.\n",
    "\n",
    "Y a medida que recorra, mientras entrena, creceremos más y más y más hasta que quizás tenga un valor mucho mayor de los parámetros w para su red neuronal.\n",
    "\n",
    "\n",
    "Y el término detención anticipada se refiere al hecho de que solo detienes el entrenamiento de su red neuronal antes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color='rosybrown'>\n",
    "\n",
    "NOTA:\n",
    "\n",
    "Estas notas estan basadas en el curso 2 de la especializacion de Deep Learning impartida por Andrew NG en la plataforma de Coursera."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

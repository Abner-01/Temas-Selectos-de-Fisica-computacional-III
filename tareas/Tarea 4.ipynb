{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T23:31:40.881412Z",
     "start_time": "2020-10-11T23:31:40.873889Z"
    }
   },
   "source": [
    "<font size=4 color='blue'>\n",
    "\n",
    "# <center> Tópico de estudio: Mortalidad por diabetes </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='blue'>\n",
    "    \n",
    "## Información sobre el tópico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Evolución de la diabetes después de un año.\n",
    "    \n",
    "En el presente trabajo, la diabetes la caracterizamos con los siguientes diez rasgos: edad, sexo, índice de masa corporal, presión arterial promedio y seis mediciones de suero sanguíneo (S1, S2, S3, S4, S5, S6).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='blue'>\n",
    "    \n",
    "## Cuantificación de esta información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Se tiene información de 442 pacientes $(m = 442)$. La respuesta de interés, $Y$, es una medida cuantitativa de la progresión de la enfermedad un año después del inicio del estudio. Los valores de $Y$ varían entre 25 y 346\n",
    "\n",
    "Fuente de la información: [diabetes data](https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html)    \n",
    "\n",
    "Artículo original: [Least-Angle-Regression_2004](./Literatura/Least-Angle-Regression_2004.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:09.525342Z",
     "start_time": "2020-10-20T17:23:09.131578Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:09.533015Z",
     "start_time": "2020-10-20T17:23:09.526914Z"
    }
   },
   "outputs": [],
   "source": [
    "# Los datos se encuentran el el archivo diabetes.csv\n",
    "\n",
    "df = pd.read_csv('diabetes.csv', sep ='\\t')\n",
    "\n",
    "# se crea el dataframe df, el cual contiene los 10 rasgos relevantes de los pacientes\n",
    "# diabeticos, así como el progreso (y) de la enfermedad un año después de comenzado el estudio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:09.552420Z",
     "start_time": "2020-10-20T17:23:09.534768Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se despliegan las primeras 5 muestras (rasgos, objetivo)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='cornflowerblue'>\n",
    "    \n",
    "  ## Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "  Despliega los últimos 15 renglones del dataframe *df*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe el código aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:09.599709Z",
     "start_time": "2020-10-20T17:23:09.554199Z"
    }
   },
   "outputs": [],
   "source": [
    "# el método describe() genera una tabla con informacion estadística de cada uno de los rasgos y del objetivo.\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se crean los histogramas para cada uno de los rasgos que caracteriza a los pacientes con diabetes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:10.163028Z",
     "start_time": "2020-10-20T17:23:09.601953Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8)) \n",
    "\n",
    "ax1 = plt.subplot(2,4,1)\n",
    "ax2 = plt.subplot(2,4,2)\n",
    "ax3 = plt.subplot(2,4,3)\n",
    "ax4 = plt.subplot(2,4,4)\n",
    "\n",
    "ax1.hist(df.AGE, bins=30, color='green',edgecolor='purple', alpha=0.5)\n",
    "ax1.set_xlabel('Age (years)', size=15)\n",
    "ax1.set_ylabel('Frequency', size=15)\n",
    "\n",
    "ax2.hist(df.SEX, bins=30, color='orange',edgecolor='purple', alpha=0.5)\n",
    "ax2.set_xlabel('Sex', size=15)\n",
    "\n",
    "ax3.hist(df.BMI, bins=30, color='red',edgecolor='purple', alpha=0.5)\n",
    "ax3.set_xlabel('Body_mass_index', size=15)\n",
    "\n",
    "ax4.hist(df.BP, bins=30, color='blue',edgecolor='purple', alpha=0.5)\n",
    "ax4.set_xlabel('Average_blood_pressure', size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:10.664852Z",
     "start_time": "2020-10-20T17:23:10.164787Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8)) \n",
    "\n",
    "ax1 = plt.subplot(2,4,1)\n",
    "ax2 = plt.subplot(2,4,2)\n",
    "ax3 = plt.subplot(2,4,3)\n",
    "ax4 = plt.subplot(2,4,4)\n",
    "\n",
    "ax1.hist(df.S1, bins=30, color='green',edgecolor='purple', alpha=0.5)\n",
    "ax1.set_xlabel('S1', size=15)\n",
    "ax1.set_ylabel('Frequency', size=15)\n",
    "\n",
    "ax2.hist(df.S2, bins=30, color='orange',edgecolor='purple', alpha=0.5)\n",
    "ax2.set_xlabel('S2', size=15)\n",
    "\n",
    "ax3.hist(df.S3, bins=30, color='red',edgecolor='purple', alpha=0.5)\n",
    "ax3.set_xlabel('S3', size=15)\n",
    "\n",
    "ax4.hist(df.S4, bins=30, color='blue',edgecolor='purple', alpha=0.5)\n",
    "ax4.set_xlabel('S4', size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:11.045266Z",
     "start_time": "2020-10-20T17:23:10.666554Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8)) \n",
    "\n",
    "ax1 = plt.subplot(2,3,1)\n",
    "ax2 = plt.subplot(2,3,2)\n",
    "ax3 = plt.subplot(2,3,3)\n",
    "\n",
    "ax1.hist(df.S5, bins=30, color='green',edgecolor='purple', alpha=0.5)\n",
    "ax1.set_xlabel('S5', size=15)\n",
    "ax1.set_ylabel('Frequency', size=15)\n",
    "\n",
    "ax2.hist(df.S6, bins=30, color='orange',edgecolor='purple', alpha=0.5)\n",
    "ax2.set_xlabel('S6', size=15)\n",
    "\n",
    "ax3.hist(df.Y, bins=30, color='purple',edgecolor='black', alpha=0.5)\n",
    "ax3.set_xlabel('Y', size=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:21:23.071130Z",
     "start_time": "2020-10-13T20:21:23.062454Z"
    }
   },
   "source": [
    "<font size=4>\n",
    "\n",
    "Para quitar cualquier posible correlación entre las muestras (los renglones del DataFrame), estos se reordenan al azar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:11.050719Z",
     "start_time": "2020-10-20T17:23:11.047329Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='cornflowerblue'>\n",
    "    \n",
    "  ## Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "Divide a las muestras originales (df) en 2 conjuntos: 90 % para el entrenamiento y 10 % para hacer inferencias (predicciones) con lo aprendido. (separa el dataframe en dos)\n",
    "\n",
    "nombra al dataframe con el 90% de  las muestras **df_train** y nombra al dataframe con el 10% restante de las muestras **df_test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:11.063764Z",
     "start_time": "2020-10-20T17:23:11.052499Z"
    }
   },
   "outputs": [],
   "source": [
    "# escribe aquí el código\n",
    "test_ratio = 0.1\n",
    "\n",
    "train_ratio = int((1.0-test_ratio)*len(df.values[:,:]))\n",
    "\n",
    "df_train = df.iloc[0:train_ratio,:]\n",
    "df_test  = df.iloc[train_ratio:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "Comprueba que las dimesniones de df_train y df_test son (397, 11) y (45,11), respectivamente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:11.075747Z",
     "start_time": "2020-10-20T17:23:11.065397Z"
    }
   },
   "outputs": [],
   "source": [
    "# escribe aquí el código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Para trabajar con los modelos se requiere que todas las variables tengan el mismo orden de magnitud. Por ello, se normalizan sus valores en las muestras que se van a emplear en el entrenamiento, tanto los rasgos $(X)$ como la variable objetivo o referencia $(Y)$:\n",
    "\n",
    "$$x_{norm} = \\dfrac{x-\\bar{x}}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='cornflowerblue'>\n",
    "    \n",
    "  ## Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "Normaliza cada rasgo así como la variable de salida, tanto para el conjunto de entrenamiento como para el conjunto de prueba. Recuerda que debes usar el promedio y desviación del conjunto de entrenamiento en ambos casos.\n",
    "\n",
    "Nombra a los dataframes con los datos normalizados **df_train_norm** y **df_test_norm**, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:11.094500Z",
     "start_time": "2020-10-20T17:23:11.077146Z"
    }
   },
   "outputs": [],
   "source": [
    "# escribe el código aquí\n",
    "df_train_norm = (df_train - df_train.mean()) / df_train.std()\n",
    "df_test_norm = (df_test - df_train.mean()) / df_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "Histogramas de las variables que se emplearán en el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:11.592444Z",
     "start_time": "2020-10-20T17:23:11.107611Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8)) \n",
    "\n",
    "ax1 = plt.subplot(2,4,1)\n",
    "ax2 = plt.subplot(2,4,2)\n",
    "ax3 = plt.subplot(2,4,3)\n",
    "ax4 = plt.subplot(2,4,4)\n",
    "\n",
    "ax1.hist(df_train_norm.AGE, bins=30, color='green',edgecolor='purple', alpha=0.5)\n",
    "ax1.set_xlabel('x1(Age)', size=15)\n",
    "ax1.set_ylabel('Frequency', size=15)\n",
    "\n",
    "ax2.hist(df_train_norm.SEX, bins=30, color='orange',edgecolor='purple', alpha=0.5)\n",
    "ax2.set_xlabel('x2(Sex)', size=15)\n",
    "\n",
    "ax3.hist(df_train_norm.BMI, bins=30, color='red',edgecolor='purple', alpha=0.5)\n",
    "ax3.set_xlabel('x3(Body_mass_index)', size=15)\n",
    "\n",
    "ax4.hist(df_train_norm.BP, bins=30, color='blue',edgecolor='purple', alpha=0.5)\n",
    "ax4.set_xlabel('x4(Average_blood_pressure)', size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.146067Z",
     "start_time": "2020-10-20T17:23:11.594277Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8)) \n",
    "\n",
    "ax1 = plt.subplot(2,4,1)\n",
    "ax2 = plt.subplot(2,4,2)\n",
    "ax3 = plt.subplot(2,4,3)\n",
    "ax4 = plt.subplot(2,4,4)\n",
    "\n",
    "ax1.hist(df_train_norm.S1, bins=30, color='green',edgecolor='purple', alpha=0.5)\n",
    "ax1.set_xlabel('x5(S1)', size=15)\n",
    "ax1.set_ylabel('Frequency', size=15)\n",
    "\n",
    "ax2.hist(df_train_norm.S2, bins=30, color='orange',edgecolor='purple', alpha=0.5)\n",
    "ax2.set_xlabel('x6(S2)', size=15)\n",
    "\n",
    "ax3.hist(df_train_norm.S3, bins=30, color='red',edgecolor='purple', alpha=0.5)\n",
    "ax3.set_xlabel('x7(S3)', size=15)\n",
    "\n",
    "ax4.hist(df_train_norm.S4, bins=30, color='blue',edgecolor='purple', alpha=0.5)\n",
    "ax4.set_xlabel('x8(S4)', size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.503067Z",
     "start_time": "2020-10-20T17:23:12.147700Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8)) \n",
    "\n",
    "ax1 = plt.subplot(2,3,1)\n",
    "ax2 = plt.subplot(2,3,2)\n",
    "ax3 = plt.subplot(2,3,3)\n",
    "\n",
    "ax1.hist(df_train_norm.S5, bins=30, color='green',edgecolor='purple', alpha=0.5)\n",
    "ax1.set_xlabel('x9(S5)', size=15)\n",
    "ax1.set_ylabel('Frequency', size=15)\n",
    "\n",
    "ax2.hist(df_train_norm.S6, bins=30, color='orange',edgecolor='purple', alpha=0.5)\n",
    "ax2.set_xlabel('x10(S6)', size=15)\n",
    "\n",
    "ax3.hist(df_train_norm.Y, bins=30, color='purple',edgecolor='black', alpha=0.5)\n",
    "ax3.set_xlabel('Y', size=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='cornflowerblue'>\n",
    "    \n",
    "  ## Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "Realiza los histogramas para los rasgos **AGE**, **BMI** y **S4** para el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escribe aquí el código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "Los valores de las variables X e Y se extraen de las columnas del DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.507790Z",
     "start_time": "2020-10-20T17:23:12.504878Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x = df_train_norm.values[:,:-1]\n",
    "train_y = df_train_norm.values[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.519443Z",
     "start_time": "2020-10-20T17:23:12.509672Z"
    }
   },
   "outputs": [],
   "source": [
    "test_x = df_test_norm.values[:,:-1]\n",
    "test_y = df_test_norm.values[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.531052Z",
     "start_time": "2020-10-20T17:23:12.520767Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = train_x.T\n",
    "x_test = test_x.T\n",
    "\n",
    "y_train = train_y.T\n",
    "y_test = test_y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.543837Z",
     "start_time": "2020-10-20T17:23:12.532806Z"
    }
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.564236Z",
     "start_time": "2020-10-20T17:23:12.545155Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "# <center> Artificial Neural Networks </center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-18T00:30:05.725975Z",
     "start_time": "2020-10-18T00:30:05.722770Z"
    }
   },
   "source": [
    "<font size=4 color='blue'>\n",
    "\n",
    "# <center> Implementación empleando el lenguaje formal Python </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T17:48:13.294187Z",
     "start_time": "2020-10-14T17:48:13.290898Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "Adecuando los datos de alimentación al sistema de aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T17:06:46.389123Z",
     "start_time": "2020-10-13T17:06:46.381702Z"
    }
   },
   "source": [
    "<font size=4>\n",
    "    \n",
    "###  Definición de la arquitectura de la red neuronal.\n",
    "\n",
    "La función ```layer_sizes()``` genera la arquitectura de la red neuronal partiendo de los datos con que se van a alimentar a la red.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.579183Z",
     "start_time": "2020-10-20T17:23:12.569309Z"
    }
   },
   "outputs": [],
   "source": [
    "def layer_sizes(X, Y, n_h):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    X -- input dataset of shape (input size, number of examples)\n",
    "    Y -- labels of shape (output size, number of examples)\n",
    "    \n",
    "    Return:\n",
    "    n_x -- the size of the input layer\n",
    "    n_h -- the size of the hidden layer\n",
    "    n_y -- the size of the output layer\n",
    "    \"\"\"\n",
    "    \n",
    "    n_x = X.shape[0]     \n",
    "    n_h = n_h\n",
    "    n_y = Y.shape[0]\n",
    "    \n",
    "    return (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.590829Z",
     "start_time": "2020-10-20T17:23:12.583563Z"
    }
   },
   "outputs": [],
   "source": [
    "n_h = 4\n",
    "n_x, n_h, n_y = layer_sizes(x_train, y_train, n_h = n_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.603382Z",
     "start_time": "2020-10-20T17:23:12.596532Z"
    }
   },
   "outputs": [],
   "source": [
    "print(n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='cornflowerblue'>\n",
    "    \n",
    "  ## Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "¿Cómo cambiaría el código de la función ```layer_sizes()``` si quisieramos usar train_x y train_y en lugar de x_train y y_train?\n",
    "\n",
    "\n",
    "Escribe la nueva función, nombrala ```layer_sizes_1()``` y pruébala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escribe aquí el código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "Gráfica de la red     \n",
    " \n",
    "<font size=4 color='black'> \n",
    "    \n",
    "Usaremos NetworkX, que es una librería escrita en Python para la creación, manipulación y estudio de la estructura, dinámica y funciones de redes complejas.\n",
    "    \n",
    "[NetworkX](https://networkx.github.io/)\n",
    "\n",
    "Para instalar NetworkX puedes usar el siguiente comando:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ conda install -c anaconda networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.784973Z",
     "start_time": "2020-10-20T17:23:12.605281Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "class Network(object):\n",
    "    \n",
    "    def  __init__ (self,sizes):\n",
    "        self.num_layers = len(sizes)\n",
    "        print(\"It has\", self.num_layers, \"layers,\")\n",
    "        self.sizes = sizes\n",
    "        print(\"with the following number of nodes per layer\",self.sizes)\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        \n",
    "    def feedforward(self, x_of_sample):\n",
    "        \"\"\"Return the output of the network F(x_of_sample) \"\"\"        \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            x_of_sample = sigmoid(np.dot(w, x_of_sample)+b)\n",
    "        return x_of_sample\n",
    "    \n",
    "    def graph(self,sizes):\n",
    "        a=[]\n",
    "        ps={}\n",
    "        Q = nx.Graph()\n",
    "        for i in range(len(sizes)):\n",
    "            Qi=nx.Graph()    \n",
    "            n=sizes[i]\n",
    "            nodos=np.arange(n)\n",
    "            Qi.add_nodes_from(nodos)\n",
    "            l_i=Qi.nodes\n",
    "            Q = nx.union(Q, Qi, rename = (None, 'Q%i-'%i))\n",
    "            if len(l_i)==1:\n",
    "                ps['Q%i-0'%i]=[i/(len(sizes)), 1/2]\n",
    "            else:\n",
    "                for j in range(len(l_i)+1):\n",
    "                    ps['Q%i-%i'%(i,j)]=[i/(len(sizes)),(1/(len(l_i)*len(l_i)))+(j/(len(l_i)))]\n",
    "            a.insert(i,Qi)\n",
    "        for i in range(len(a)-1):\n",
    "            for j in range(len(a[i])):\n",
    "                for k in range(len(a[i+1])):\n",
    "                    Q.add_edge('Q%i-%i' %(i,j),'Q%i-%i' %(i+1,k))\n",
    "        nx.draw(Q, pos = ps)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.852839Z",
     "start_time": "2020-10-20T17:23:12.786355Z"
    }
   },
   "outputs": [],
   "source": [
    "layers = [n_x, n_h, n_y]\n",
    "net = Network(layers)\n",
    "net.graph(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='cornflowerblue'>\n",
    "    \n",
    "  ## Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Supón que a partir de un estudio concluimos que $y$ (el nivel de progreso de la enfremedad) no depende de la edad y el sexo (es solo un ejemplo, en la realidad puede no ser así), ¿cuántos nodos debería tener cada una de las capas de una red neuronal con dos capas?\n",
    "\n",
    "Responde esta pregunta ilustrando la red neuronal con networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escribe aquí el código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='cornflowerblue'>\n",
    "    \n",
    "  ## Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Supón que a partir del nivel de progreso de la enfermedad se puede concluir que para ciertos valores se concluye que el progreso es avanzado, medio y bajo. Es decir, la inferencia de la red es avanzado, medio o bajo en lugar de solo un numero que indica el nivel de progreso de la enfermedad.\n",
    "\n",
    "¿cuántos nodos debería tener cada una de las capas de una red neuronal con dos capas?\n",
    "\n",
    "Responde esta pregunta ilustrando la red neuronal con networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escribe aquí el código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "    \n",
    " 1. Inicialización de los pesos y el bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "### Se inicializan las variables del algoritmo que define la relación entre X y Y. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "Debido a que las variables X y Y fueron normalizadas a distribuciones con un deviación estándar, las variables $w$ se inicializan con valores pequeños, mientras que los biases se inicializan a cero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "La función ```initialize_parameters()``` inicializa a los pesos $W$ y el bias $b$. \n",
    "\n",
    "Dado que se tiene un conjunto de variables independientes, se debe definir un peso para cada variable, esto para una sola neurona de la siguiente capa. \n",
    "\n",
    "Entonces $W_1$ ahora es una matriz de tamaño $(n_h, n_x)$, en donde $n_h$ es el número de nodos en la capa interna y $n_x$ es el número de nodos en la capa de entrada, es decir, es el número de variables independientes.\n",
    "\n",
    "Por cada neurona en la capa interna hay un bias, por lo que ahora $b_1$ es un vector de tamaño $(n_h, 1)$. \n",
    "\n",
    "En general para cada par de capas consecutivas debe haber un $W$ y un $b$.\n",
    "\n",
    "Generalizando:\n",
    "\n",
    "$W_i$ y $b_i$ son los parámetros a definir entre la capa $i$ y la capa $i+1$. Si la capa $i$ tiene $n_i$ neuronas y la capa $i+1$ tiene $n_{i+1}$ neuronas entonces, las dimensiones de $W_i$ son $(n_{i+1}, n_i)$ y las dimensiones de $b_i$ son $(n_{i+1}, 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.862688Z",
     "start_time": "2020-10-20T17:23:12.854878Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- int: size of the input layer\n",
    "    n_h -- int: size of the hidden layer\n",
    "    n_y -- int: size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "    params -- python dictionary containing your parameters:\n",
    "                    W1 -- weight matrix of shape (n_h, n_x)\n",
    "                    b1 -- bias vector of shape (n_h, 1)\n",
    "                    W2 -- weight matrix of shape (n_y, n_h)\n",
    "                    b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(2) \n",
    "    \n",
    "    W1 = np.reshape(np.random.uniform(-0.1, 0.1, n_h*n_x), (n_h, n_x))  \n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.reshape(np.random.uniform(-0.1, 0.1, n_y*n_h), (n_y, n_h))    \n",
    "    b2 = np.zeros((n_y, 1))\n",
    "     \n",
    "    assert (W1.shape == (n_h, n_x))\n",
    "    assert (b1.shape == (n_h, 1))\n",
    "    assert (W2.shape == (n_y, n_h))\n",
    "    assert (b2.shape == (n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.877400Z",
     "start_time": "2020-10-20T17:23:12.864822Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = initialize_parameters(n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='cornflowerblue'>\n",
    "    \n",
    "  ## Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "¿Cuáles son las dimensiones de W1 y W2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escribe aquí el código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='cornflowerblue'>\n",
    "    \n",
    "  ## Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "Obten las palabras clave del diccionario *parameters* (Recuerda que hay un atributo que indica los keyword de un diccionario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escribe aquí el código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T18:02:21.703636Z",
     "start_time": "2020-10-14T18:02:21.700427Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "2. Conexión entre las neuronas de capas contiguas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "La función ```propagate()``` realiza la combinacion lineal entre los valores de salida de los nodos de una capa con los pesos y bias definidos entre esa capa y la siguiente. \n",
    "\n",
    "La función de activación que se aplica a esta combinación, es para considerar efectos no lineales.\n",
    "\n",
    "\n",
    "___\n",
    "\n",
    "Funciones de activación disponibles en la presente notebook: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.892019Z",
     "start_time": "2020-10-20T17:23:12.878669Z"
    }
   },
   "outputs": [],
   "source": [
    "#Función para considerar los efectos no lineales.\n",
    "#En el presente caso se considera un modelo completamente lineal.\n",
    "#Por ello la función es la identidad.\n",
    "\n",
    "def identity(z):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- z\n",
    "    \"\"\"\n",
    "    s = np.multiply(1.0,z)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.903601Z",
     "start_time": "2020-10-20T17:23:12.893253Z"
    }
   },
   "outputs": [],
   "source": [
    "def identity_derivative(z):\n",
    "    return np.ones(len(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.914927Z",
     "start_time": "2020-10-20T17:23:12.905109Z"
    }
   },
   "outputs": [],
   "source": [
    "def tanh(z):\n",
    "    \"\"\"\n",
    "    Compute the tanh of z\n",
    "\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- tanh(z)\n",
    "    \"\"\"\n",
    "    return np.tanh(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.926265Z",
     "start_time": "2020-10-20T17:23:12.916623Z"
    }
   },
   "outputs": [],
   "source": [
    "def tanh_derivative(z):\n",
    "    return 1-np.square(tanh(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.937706Z",
     "start_time": "2020-10-20T17:23:12.927652Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.949736Z",
     "start_time": "2020-10-20T17:23:12.939178Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid_derivative(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='cornflowerblue'>\n",
    "    \n",
    "  ## Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "Grafica la función sigmoid y la función tanh. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escribe aquí el código\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.962291Z",
     "start_time": "2020-10-20T17:23:12.951620Z"
    }
   },
   "outputs": [],
   "source": [
    "def propagate(X, Y, parameters):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    X -- input data of size (n_x, m)\n",
    "    parameters -- python dictionary containing your parameters (output of initialization function)\n",
    "    \n",
    "    Returns:\n",
    "    A2 -- The sigmoid output of the second activation\n",
    "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve each parameter from the dictionary \"parameters\"\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    # Zi es la combinación lineal entre x y w\n",
    "    # Ai es la aplicación de una función de activación a Zi\n",
    "    \n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = Z2\n",
    "    \n",
    "    assert(A2.shape == (1, X.shape[1]))\n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    m = Y.shape[1] # number of samples\n",
    "\n",
    "    cost = (1/m)*np.sum((Y-A2)**2)\n",
    "    cost = np.squeeze(cost)     \n",
    "    \n",
    "    assert(isinstance(cost, float))\n",
    "\n",
    "    # Calculo de derivadas\n",
    "        \n",
    "    dZ2 = 2*(A2-Y)\n",
    "    dW2 = (1/m)*np.dot(dZ2, A1.T)\n",
    "    db2 = (1/m)*np.sum(dZ2, axis = 1, keepdims = True)\n",
    "    dZ1 = np.dot(W2.T, dZ2)*tanh_derivative(A1)\n",
    "    dW1 = (1/m)*np.dot(dZ1, X.T)\n",
    "    db1 = (1/m)*np.sum(dZ1, axis = 1, keepdims = True)\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    \n",
    "    return A2, cache, cost, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.976704Z",
     "start_time": "2020-10-20T17:23:12.963652Z"
    }
   },
   "outputs": [],
   "source": [
    "def validation(X, Y, parameters):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    X -- input data of size (n_x, m)\n",
    "    Y -- output data of size (n_y, m)\n",
    "    parameters -- python dictionary containing your parameters (output of initialization function)\n",
    "    \n",
    "    Returns:\n",
    "    A2 -- The sigmoid output of the second activation\n",
    "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\"\n",
    "    cost -- the value of cost\n",
    "    grads -- a dictionary contains derivatives to update parameters\n",
    "    \"\"\"\n",
    "    # Regresa cada parametro del diccionario \"parameters\"\n",
    "    \n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    # Pasos 1 y 2:\n",
    "    \n",
    "    # Zi es la combinacion lineal entre x y w\n",
    "    # Ai es la aplicacion de una funcion de activacion a Zi:\n",
    "    \n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = Z2\n",
    "    \n",
    "    # se verifican las dimensiones de A2:\n",
    "    \n",
    "    assert(A2.shape == (1, X.shape[1]))\n",
    "\n",
    "    # Paso 3:\n",
    "    \n",
    "    # numero de muestras:\n",
    "    \n",
    "    m = Y.shape[1] \n",
    "    \n",
    "    # se calcula el costo:\n",
    "\n",
    "    cost = (1/m)*np.sum((Y-A2)**2)\n",
    "    \n",
    "    # Asegura que cost sea un escalar:\n",
    "    \n",
    "    cost = np.squeeze(cost)      \n",
    "                                \n",
    "    assert(isinstance(cost, float))  \n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='cornflowerblue'>\n",
    "    \n",
    "  ## Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "¿Cuáles son las dimensiones de Z1, A1, Z2 y A2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escribe aquí el código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "3. Cálculo de la función de costo durante la optimización de los parámetros que definen al modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Recordemos que la función de costo, $J$, nos permite saber qué tan bien se esta ajustando el modelo a la variable objetivo de las muestras. \n",
    "\n",
    "Para ello se buscan los parámetros que minimicen a esta función. \n",
    "\n",
    "En el presente caso, la función de costo está definida por la relación siguiente: \n",
    "\n",
    "$$J = \\dfrac{1}{m}\\sum_{i=1}^{m}(y_i-a_i)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:12.994936Z",
     "start_time": "2020-10-20T17:23:12.978202Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_cost(A2, Y, parameters):\n",
    "    \"\"\"\n",
    "    Computes the cross-entropy cost given in equation (13)\n",
    "    \n",
    "    Arguments:\n",
    "    A2 -- The sigmoid output of the second activation, of shape (1, number of examples)\n",
    "    Y -- \"true\" labels vector of shape (1, number of examples)\n",
    "    parameters -- python dictionary containing your parameters W1, b1, W2 and b2\n",
    "    \n",
    "    Returns:\n",
    "    cost -- cross-entropy cost given equation (13)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1] # number of samples\n",
    "    cost = (1/m)*np.sum((Y-A2)**2) \n",
    "    cost = np.squeeze(cost)    \n",
    "    assert(isinstance(cost, float))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Para encontrar a los valores óptimos de los parámetros, estos se acualizan en cada época empleando el algoritmo de gradiente descendente. El cual esta definido por la siguientes relaciones:\n",
    "\n",
    "$$ \\omega := \\omega - \\alpha \\dfrac{\\partial J(\\omega, b)}{\\partial \\omega}$$\n",
    "\n",
    "$$ b := b - \\alpha \\dfrac{\\partial J(\\omega, b)}{\\partial b}$$\n",
    "\n",
    "Por ello es necesario calcular las derivadas del costo respecto a cada uno de los parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:13.010654Z",
     "start_time": "2020-10-20T17:23:12.996218Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculation_of_derivatives(parameters, cache, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation using the instructions above.\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing our parameters \n",
    "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\".\n",
    "    X -- input data of shape (2, number of examples)\n",
    "    Y -- \"true\" labels vector of shape (1, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    grads -- python dictionary containing your gradients with respect to different parameters\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    W1 = parameters[\"W1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    A1 = cache[\"A1\"]\n",
    "    A2 = cache[\"A2\"]\n",
    "    \n",
    "    # Calculo de derivadas\n",
    "    \n",
    "    dZ2 = 2*(A2-Y)\n",
    "    dW2 = (1/m)*np.dot(dZ2, A1.T)\n",
    "    db2 = (1/m)*np.sum(dZ2, axis = 1, keepdims = True)\n",
    "    dZ1 = np.dot(W2.T, dZ2)*(1-np.power(A1, 2))\n",
    "    dW1 = (1/m)*np.dot(dZ1, X.T)\n",
    "    db1 = (1/m)*np.sum(dZ1, axis = 1, keepdims = True)\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "4. Optimizacion de los pesos y los bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:13.023183Z",
     "start_time": "2020-10-20T17:23:13.012069Z"
    }
   },
   "outputs": [],
   "source": [
    "def optimize(parameters, grads, learning_rate = 0.1):\n",
    "    \"\"\"\n",
    "    Updates parameters using the gradient descent update rule given above\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients \n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "    \"\"\"\n",
    "    # Retrieve each parameter from the dictionary \"parameters\"\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    # Retrieve each gradient from the dictionary \"grads\"\n",
    "    dW1 = grads[\"dW1\"]\n",
    "    db1 = grads[\"db1\"]\n",
    "    dW2 = grads[\"dW2\"]\n",
    "    db2 = grads[\"db2\"]\n",
    "    \n",
    "    # Update rule for each parameter\n",
    "    W1 = W1-learning_rate*dW1\n",
    "    b1 = b1-learning_rate*db1\n",
    "    W2 = W2-learning_rate*dW2\n",
    "    b2 = b2-learning_rate*db2\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "5. Las predicciones se realizan con los parametros óptimos encontrados en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:13.040157Z",
     "start_time": "2020-10-20T17:23:13.024797Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(parameters, X, Y):\n",
    "    \"\"\"\n",
    "    Using the learned parameters, predicts a class for each example in X\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    X -- input data of size (n_x, m)\n",
    "    \n",
    "    Returns\n",
    "    predictions -- vector of predictions of our model\n",
    "    \"\"\"\n",
    "    predictions =  []\n",
    "    A2, cache, cost, grads = propagate(X, Y, parameters)\n",
    "    predictions = identity(A2) \n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "    \n",
    "Las funciones anteriores se integran para generar, entrenar y validar la red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:13.057158Z",
     "start_time": "2020-10-20T17:23:13.041494Z"
    }
   },
   "outputs": [],
   "source": [
    "def nn_model(X, Y, val_ratio, n_h, epochs, alpha, print_cost=False):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- dataset of shape (2, number of examples)\n",
    "    Y -- labels of shape (1, number of examples)\n",
    "    n_h -- size of the hidden layer\n",
    "    num_iterations -- Number of iterations in gradient descent loop\n",
    "    print_cost -- if True, print the cost every 1000 iterations\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_ratio = int((1-val_ratio)*X.shape[1])\n",
    "    X_dev = X[:,train_ratio:]\n",
    "    Y_dev = Y[:,train_ratio:]\n",
    "\n",
    "    X = X[:,:train_ratio]\n",
    "    Y = Y[:,:train_ratio]\n",
    "    \n",
    "    print(\"Train\",X.shape,Y.shape)\n",
    "    print(\"val\",X_dev.shape,Y_dev.shape)\n",
    "    np.random.seed(2)    \n",
    "    n_x, n_h, n_y = layer_sizes(X, Y, n_h = n_h)\n",
    "        \n",
    "    # Initialize parameters, then retrieve W1, b1, W2, b2. Inputs: \"n_x, n_h, n_y\". Outputs = \"W1, b1, W2, b2, parameters\".\n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"] \n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    \n",
    "    costs=[]\n",
    "    costs_dev = []\n",
    "    params = []\n",
    "    \n",
    "    for i in range(0, epochs):\n",
    "         \n",
    "        A2, cache, cost, grads = propagate(X, Y, parameters)\n",
    "    \n",
    "        cost_dev = validation(X_dev, Y_dev, parameters)\n",
    " \n",
    "        parameters = optimize(parameters, grads, alpha)\n",
    "        \n",
    "        params.append(parameters)\n",
    "        \n",
    "        costs.append(cost)\n",
    "        \n",
    "        costs_dev.append(cost_dev)\n",
    "                \n",
    "        # Print the cost every 1000 iterations\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost and Cost_val in epoch %i: %f %f\" %(i, cost, cost_dev))\n",
    "            \n",
    "    return parameters, costs, params, costs_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T17:25:36.366411Z",
     "start_time": "2020-10-13T17:25:36.359140Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "Entrenamiento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='cornflowerblue'>\n",
    "    \n",
    "  ## Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Cambia el valor de la tasa de aprendizaje (alfa), el número de nodos en la capa oculta, la proporción de los datos a usar para la validación y el número de epocas de tal manera que las curvas de costo para el entrenamiento y la validación sean lo mas parecidas posibles. \n",
    "\n",
    "Cambia estos hiper-parámetros a prueba y error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:13.436867Z",
     "start_time": "2020-10-20T17:23:13.058576Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "learning_rate = 0.001\n",
    "val_ratio = 0.1\n",
    "n_h = 4\n",
    "\n",
    "opt_parameters, costs, params, costs_dev = nn_model(x_train, y_train, val_ratio=val_ratio, \n",
    "                                                    n_h = n_h, epochs = epochs, alpha=learning_rate, print_cost=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:13.573105Z",
     "start_time": "2020-10-20T17:23:13.438770Z"
    }
   },
   "outputs": [],
   "source": [
    "costs = np.squeeze(costs)\n",
    "plt.plot(costs, color='red')\n",
    "plt.plot(costs_dev, color='green')\n",
    "\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['cost_train', 'cost_validation']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:22:14.197314Z",
     "start_time": "2020-10-20T17:22:14.188557Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Para calcular la precision del modelo se usa MSE:\n",
    "\n",
    "$$100-MSE*100$$\n",
    "\n",
    "es decir\n",
    "\n",
    "$$100-(\\dfrac{1}{m}\\Sigma_{i}(y_{i}-a_{i})^2)*100$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:13.579710Z",
     "start_time": "2020-10-20T17:23:13.574921Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_train = predict(opt_parameters, x_train, y_train)\n",
    "\n",
    "print(\"train accuracy: {} %\".format(100 - np.mean(np.power(predictions_train-y_train, 2)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T17:23:13.592106Z",
     "start_time": "2020-10-20T17:23:13.581191Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_test = predict(opt_parameters, x_test, y_test)\n",
    "print(\"test accuracy: {} %\".format(100 - np.mean(np.power(predictions_test-y_test, 2)) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
